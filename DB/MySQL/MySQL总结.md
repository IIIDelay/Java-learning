# InnoDB四大特性

#### 1、插入缓冲(insert buffer)

> 插入缓冲(Insert Buffer/Change Buffer): 提升插入性能, change buffering是insert buffer的加强, insert buffer只针对insert有效, change buffering对insert、delete、update(delete+insert)、purge都有效

使用插入缓冲的条件: 

- 非聚集索引(辅助索引)
- 非唯一索引

Change buffer是作为buffer pool中的一部分存在。`Innodb_change_buffering`参数缓存所对应的操作(update会被认为是delete+insert): 

- `all`: 默认值, 缓存insert, delete, purges操作
- `none`: 不缓存
- `inserts`: 缓存insert操作
- `deletes`: 缓存delete操作
- `changes`: 缓存insert和delete操作
- `purges`: 缓存后台执行的物理删除操作

`innodb_change_buffer_max_size`参数: 控制使用的大小, 默认25%, 最大可设置50%, 如果mysql实例中有大量的修改操作, 可考虑增大该参数；

对满足插入缓存条件的插入, 每一次的插入不是写到索引页中, 而是: 

1. 会先判断插入的非聚集索引页是否在缓冲池中, 如果在直接插入；
2. 如果不在, 则先放到insert buffer中, 再按照一定的频率进行合并操作, 再写会磁盘；
3. 通常可以将多个插入合并到一个操作中, 目的是为了减少随机IO带来的性能损耗；

这样通常能将多个插入合并到一个操作中, 目的还是为了**减少随机IO带来性能损耗**。

**上面提过在一定频率下进行合并, 那所谓的频率是什么条件**？

1. 辅助索引页被读取到缓冲池中。正常的select先检查Insert Buffer是否有该非聚集索引页存在, 若有则合并插入。
2. 辅助索引页没有可用空间。空间小于1/32页的大小, 则会强制合并操作。
3. Master Thread 每秒和每10秒的合并操作。

insert buffer的数据结构是一颗B+树；

- 全局只有一颗insert buffer B+树, 负责对所有表的辅助索引进行insert buffer；
- 这颗B+树放在共享表空间中, 试图通过独立表空间ibd文件恢复表中数据时, 往往会导致check table失败, 因为表中的辅助索引中的数据可能还在insert buffer中, 也就是共享表空间中, 所以ibd文件恢复后, 还需要repair
  table操作来重建表上所有的辅助索引；

#### 2、二次写(double write)

1. doublewrite缓存位于系统表空间的存储区域, 用来缓存innodb的数据页从innodb buffer pool中flush之后并写入到数据文件之前；
2. 当操作系统或数据库进程在数据页写入磁盘的过程中崩溃, 可以在doublewrite缓存中找到数据页的备份, 用来执行crash恢复；
3. 数据页写入到doublewrite缓存的动作所需要的io消耗要小于写入到数据文件的消耗, 因为此写入操作会以一次大的连续块的方式写入；

![二次写过程](images/MySQL%E6%80%BB%E7%BB%93/20210627104446.png)

从上图可知: 

1. 内存中doublewrite buffer大小2M；物理磁盘上共享表空间中连续的128个页, 也就是2个区(extent)大小同样为2M
2. 对缓冲池脏页进行刷新时, 不是直接写磁盘。流程: 
   1. 通过memcpy()函数将脏页先复制到内存中的doublewrite buffer
   2. 通过doublewrite分两次, 每次1M顺序的写入共享表空间的物理磁盘上。这个过程中, doublewrite页是连续的, 因此这个过程是顺序的, 所以开销并不大；
   3. 完成doublewrite页的写入后, 再将doublewrite buffer中的页写入各个表空间文件中, 此时写入是离散的, 可能会较慢；
   4. 如果操作系统在第三步的过程中发生了崩溃, 在恢复过程中, 可以从共享表空间中的doublewrite中找到该页的一个副本, 将其复制到表空间文件中, 再应用重做日志；

#### 3、自适应hash索引(ahi)

> innodb存储引擎会监控对表上二级索引的查找, 如果发现某二级索引被频繁访问, 此索引成为热数据, 建立hash索引以提升查询速度, 此建立是自动建立哈希索引, 故称为自适应哈希索引(adaptive hash index)。

该属性通过`innodb_adapitve_hash_index`开启, 也可以通过`—skip-innodb_adaptive_hash_index`参数关闭

注意事项: 

- 自适应哈希索引会占用innodb buffer pool
- 只适合搜索等值(=)的查询, 对于范围查找等操作, 是不能使用的
- 极端情况下, 自适应hash索引才有比较大的意义, 可以降低逻辑读

#### 4、预读(read ahead)

> **extent 定义**: 表空间(tablespace 中的一组 page)

InnoDB使用两种预读算法来提高I/O性能: 线性预读(linear read-ahead)和随机预读(randomread-ahead)。

- 线性预读: 以extent为单位, 将下一个extent提前读取到buffer pool中；
- 随机预读: 以extent中的page为单位, 将当前extent中的剩余的page提前读取到buffer pool中；

线性预读一个重要参数: innodb_read_ahead_threshold, 控制什么时间(访问extent中多少页的阈值)触发预读；

- 默认: 56, 范围: 0～64, 值越高, 访问模式检查越严格；
- 没有该变量之前, 当访问到extent最后一个page时, innodb会决定是否将下一个extent放入到buffer pool中；

随机预读说明: 

- 当同一个extent的一些page在buffer pool中发现时, innodb会将extent中剩余page一并读取到buffer pool中；
- 随机预读给innodb code带来一些不必要的复杂性, 性能上也不稳定, 在5.5版本已经废弃, 如果启用, 需要修改变量: innodb_random_read_ahead为ON；



# Mysql数据库要用B+树存储索引？

## 背景

在面试中, mysql的索引结构应该是高频考点了。

> 面试官: 你了解mysql的索引吗？
>
> 我: 索引是一种协助快速查询数据的一种数据结构。
>
> 面试官: 那你知道mysql中存储索引用的什么数据结构吗？
>
> 我: 一般使用B+数吧。
>
> 面试官: B+树的查询时间大概是多少？
>
> 我: 和树的高度有关, log(n)
>
> 面试官: **mysql的索引结构为什么选用B+树, 而不是选择二叉排序树、平衡二叉树、红黑树以及Hash呢？**
>
> 我: ……

**mysql的索引结构为什么选用B+树？** 这个问题之前在总结 **mysql索引** 的时候已经总结过了, 但是感觉还是没有总结到位, 考虑的方面还不够全面, 所以这篇文章再来细细地捋一下。

数据结构选型以如下图的user表进行分析: 

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626100234.png" alt="user表部分数据示例" style="zoom: 50%;" />

## Hash 表

> 哈希算法: 也叫散列算法, 就是把任意值(key)通过哈希函数变换为固定长度的 key 地址, 通过这个地址进行数据查询的数据结构。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626100002.png" alt="哈希表原理" style="zoom:67%;" />

如果需要检索`id=7`的数据, sql如下: 

```sql
select *
from user
where id = 7;
```

哈希算法快速检索数据的计算过程: 首先计算存储 id=7 的数据的物理地址 addr=hash(7)=4231, 而 4231 映射的物理地址是 0x77, 0x77 就是 id=7 存储的额数据的物理地址, 通过该独立地址可以找到对应
user_name='g'这个数据。

但是hash算法可能出现**碰撞问题**, 即hash函数可能计算相同的key值, 不同的key映射到了同一个结果。解决碰撞问题的常见方法是**链地址法**
: 碰撞数据使用链表连接, 计算hash值后, 判断该值如果有碰撞, 遍历到链表, 直到找到真正的key所对应的数据为止。

![hash碰撞-链地址法](images/MySQL%E6%80%BB%E7%BB%93/20210626101110.png)

从算法时间复杂度分析来看, 哈希算法**时间复杂度为 O(1)**, 检索速度非常快。比如查找 id=7 的数据, 哈希索引只需要计算一次就可以获取到对应的数据, 检索速度非常快。但是 Mysql 并没有采取哈希作为其底层算法。

```
select * from user where id >3;
```

即hash算法针对范围查找效率太低, 需要把所有数据找出来加载到内存, 然后再在内存里筛选筛选目标范围内的数据。

Hash索引仅仅适合**等值查询**, 如果是**范围查询**和**排序**的话, 它的性能就会大大下降。

而往往我们的业务都是复杂的查询, 我们数据库大部分瓶颈也是在查询上, 所以Hash索引在大部分场景下是不适合的。

**总结: hash表可以快速检索单条数据, 但是范围查询和排序的效率太低, 而且可能需要Hash碰撞, 极端情况下效率低。所以不适合作为MySQL的索引数据结构**。

## 二叉查找树(BST)

为了**解决hash表范围查找效率低的问题**, 我们考虑二叉查找树。

二叉查找树支持快速查找数据, 时间复杂度为O(logn)。如下图所示, 只需计算三次即可找到`id=7`的数据。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626101831.png" alt="image-20210626101831123" style="zoom:67%;" />

二叉查找数按序排列(从左到右升序), 如果想找到`id>5`的数据, 只需要找到**节点6及其右子树**的数据即可, 范围查找比较容易实现。

**普通二叉树的致命缺点**: 极端情况下会退化为线性链表, 时间复杂度为O(n), 性能急剧下降, 如下图: 

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626102314.png" alt="二叉树退化为线性链表"  />

数据库表的主键id一般为自增, 上述的线性结构查找问题必然出现, 而且频率还很高。

**总结: 二叉查找数查询效率高, 而且可以解决hash表范围查询效率低的问题, 但是会频繁出现不平衡退化问题导致查询效率低的问题, 所以不适合作为MySQL索引的数据结构**。

## 红黑树

二叉查找树不平衡, 可以通过树节点的自动旋转和调整来解决, 从而保证二叉树的查找性能。最常见的思路是平衡二叉树和红黑树。

红黑树可以自动调整树的结构, 当二叉树不平衡时, 红黑树自动左右旋转和节点变色, 保持基本平衡, 时间复杂度为O(logn), 查询效率不会降低。如下图, 红黑树查找`id=7`的节点只需要查找4次: 

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626105121.png" alt="红黑树查找节点" style="zoom: 80%;" />

**但是红黑树也有缺点, 即“右倾”现象**(参看下图), 虽然没有二叉树退化那么夸张, 但数据库主键基本都是自增, 面对成千上百万的数据, 这查询效率可想而知。

![红黑树“右倾”现象](images/MySQL%E6%80%BB%E7%BB%93/20210626105920.png)

**总结: 红黑树查询效率与二叉查找树相似, 极端退化情况比平衡二叉树好, 但是也没能达到预期, 所以不适合MySQL索引的数据结构**。

## 平衡二叉树(AVL)

既然二叉树不平衡, 为了解决其极端情况下退化为线性链表的问题, 我们考虑使用平衡二叉树。

AVL 树顺序插入 1~7 个节点, 查找 id=7 所要比较节点的次数为 3。

AVL 树插入 1~16 个节点, 查找 id=16 需要比较的节点数为 4。从查找效率而言, AVL 树查找的速度要高于红黑树的查找效率(AVL 树是 4 次比较, 红黑树是 6 次比较)。

从树的形态看来, AVL 树不存在红黑树的“右倾”问题。大量的顺序插入不会导致查询性能的降低, 这从根本上解决了红黑树的问题。

**AVL 树的优点**: 

- 查询效率高O(logn), 不存在极端情况。
- 可以进行范围查找和排序。

**但是为什么不选取AVL树作为MySQL索引的数据结构**？

**主要是磁盘IO因素的影响**。如果使用AVL树, 每一个树节点, 只存储一个数据。如果查询`id=7`的数据, 需要比对三次树节点, 即进行三次磁盘IO操作, 如果数据量大了, 那磁盘IO的次数会很高, 消耗大量的时间。

所以, **设计数据库索引的时候, 还需要考虑怎么尽可能减少磁盘的IO次数**。

> 注意, 我们说的平衡二叉树结构, 指的是逻辑结构上的平衡二叉树, 其物理实现是数组。然后由于在**逻辑结构上相近的节点在物理结构上可能会差很远**。因此, **每次读取的磁盘页的数据中有许多是用不上的**。因此, 查找过程中要进行许多次的磁盘读取操作。

**磁盘读取1B和1KB的数据消耗的时间基本是一样的, 所以可以在一个节点存储更多的数据, 即一次磁盘IO读取更多数据, 即可解决问题。所以就考虑到了B树**。

## B树

B树是一种平衡多路搜索树, 它的每个节点可以拥有多于两个孩子节点。M路的B树最多能拥有M个孩子节点。

平衡二叉树没能充分利用磁盘预读功能, 而B树是为了**充分利用磁盘预读功能**来而创建的一种数据结构, 也就是说B树就是为了作为索引才被发明出来的的。

> **为啥要设计成多路呢？**
>
> 是为了进一步降低树的高度。路数越多, 树的高度越低。
>
> **如果设计成无限多路可以吗？**
>
> 设计成无限多路, 树会退化成有序数组。mysql默认一个节点也就是一次IO读取数据的大小刚好是16K, 一次IO是为了加载一个节点, 读取一页数据, 这样可以读更多的数据。如果是有序数组, 这样反而不好, 因为数据量太大一次不能够将数据加载到内存。
>
> **你知道B树一般用在哪里吗？**
>
> B树做文件系统的索引比较多。
>
> **为什么文件系统的索引喜欢用B树而不用红黑树或者有序数组呢?**
>
> 文件系统和数据库的索引都是存在硬盘上的, 并且如果数据量大的话, 不一定能一次性加载到内存中。
>
> **如果一棵树都无法一次性加载进内存, 你该怎么查找呢?**
>
> 这时候B树的多路存储威力就出来了, 可以每次加载B树的一个节点, 然后一步步往下找。
>
> 如果在内存中,红黑树比B树效率更高, 但是涉及到磁盘操作, B树就更优了。



> **磁盘IO与预读**
>
> 考虑到磁盘IO是非常高昂的操作, 计算机操作系统做了一些优化, 当一次IO时, 不光把当前磁盘地址的数据, 而是把相邻的数据也都读取到内存缓冲区内, 因为局部预读性原理告诉我们, 当计算机访问一个地址的数据的时候, 与其相邻的数据也会很快被访问到。
>
> mysql每一次IO读取的数据我们称之为一页(page)。



**如果每个节点限制最多存储两个key(即二叉树), 一个节点如果超过两个key会自动分裂。**

比如下面这个存储了 7 个数据 B 树, 只需要查询两个节点就可以知道 id=7 这数据的具体位置, 也就是两次磁盘 IO 就可以查询到指定数据, 优于 AVL 树。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626112940.png" alt="B树7节点(限制单节点key=2)" style="zoom:80%;" />

如果是一个存储了 16 个数据的 B 树, 同样每个节点最多存储 2 个 key, 查询 id=16 这个数据需要查询比较 4 个节点, 也就是经过 4 次磁盘 IO。看起来查询性能与 AVL 树一样。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626115100.png" alt="B树16节点(限制单节点key=2)" style="zoom:80%;" />

**如果限制每个节点可以存储6个key。**

一个存储了 7 个数据的 B 树, 查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626115252.png" alt="B树7节点(限制单节点key=6)" style="zoom:80%;" />



一个存储了 16 个数据的 B 树, 查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。相对于 AVL 树而言磁盘 IO 次数降低为一半。

![B树16节点(限制单节点key=6)](images/MySQL%E6%80%BB%E7%BB%93/20210626115329.png)

**B 树作数据库索引优点**: 

- 优秀检索速度, 时间复杂度: B 树的查找性能等于 O(h*logn), 其中 h 为树高, n 为每个节点关键词的个数；
- 尽可能少的磁盘 IO, 加快了检索速度；
- 可以支持范围查找。

**缺点**: 

如果是多条的话, B树需要做**局部的中序遍历, 可能要跨层访问**。

## B+树

比B树更适合作为索引的结构是B+树。MySQL中也是使用B+树作为索引。它是B树的变种, 因此是基于B树来改进的。为什么B+树会比B树更加优秀呢？

- B树: 有序数组+平衡多叉树；
- B+树: 有序数组链表+平衡多叉树；

**B+树的关键字全部存放在叶子节点中, 非叶子节点用来做索引, 而叶子节点中有一个指针指向一下个叶子节点**。做这个优化的目的是为了**提高区间访问的性能**。而正是这个特性决定了B+树更适合用来存储外部数据。

![B+树](images/MySQL%E6%80%BB%E7%BB%93/20210626115803.png)

> B+树还有一个最大的好处, 方便扫库, B树必须用中序遍历的方法按序扫库, 而B+树直接从叶子结点挨个扫一遍就完了, B+树支持range-query非常方便, 而B树不支持。这是数据库选用B+树的最主要原因。
>
> ——梁斌《走进搜索引擎》

比如要查 5-10之间的, B+树一把到5这个标记, 再一把到10, 然后串起来就行了, B树就非常麻烦。

只查询一条记录, B树性能会好于B+树, 因为B树的高度总体要比B+树矮。但是更多的业务需要的却是范围查询。

> 数据库索引采用B+树的主要原因是B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题, B+树应运而生。
>
> B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的, 而B树不支持这样的操作(或者说效率太低)。

**在数据库中基于范围的查询是非常频繁的, 因此MySQL最终选择的索引结构是B+树而不是B树。**

B+树的查找过程: 

![B+树的查找过程](images/MySQL%E6%80%BB%E7%BB%93/202109232157672.jpeg)

如图所示, 如果要查找数据项29, 那么首先会把磁盘块1由磁盘加载到内存, 此时发生一次IO, 在内存中用二分查找确定29在17和35之间, 锁定磁盘块1的P2指针, 内存时间因为非常短(相比磁盘的IO)可以忽略不计, 通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存, 发生第二次IO, 29在26和30之间, 锁定磁盘块3的P2指针, 通过指针加载磁盘块8到内存, 发生第三次IO, 同时内存中做二分查找找到29, 结束查询, 总计三次IO。

真实的情况是, 3层的b+树可以表示上百万的数据, 如果上百万的数据查找只需要三次IO, 性能提高将是巨大的, 如果没有索引, 每个数据项都要发生一次IO, 那么总共需要百万次的IO, 显然成本非常非常高。

## B*树

B*Tree是B+树的变体, 在B+Tree的非根和非叶子结点再增加指向兄弟的指针；

B*树定义了非叶子结点关键字个数至少为(2/3)*M, 即块的最低使用率为2/3(代替B+树的1/2)；

B+树的分裂: 当一个结点满时, 分配一个新的结点, 并将原结点中1/2的数据复制到新结点, 最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点, 而不会影响兄弟结点, 所以它不需要指向兄弟的指针；

B*
树的分裂: 当一个结点满时, 如果它的下一个兄弟结点未满, 那么将一部分数据移到兄弟结点中, 再在原结点插入关键字, 最后修改父结点中兄弟结点的关键字(因为兄弟结点的关键字范围改变了)；如果兄弟也满了, 则在原结点与兄弟结点之间增加新结点, 并各复制1/3的数据到新结点, 最后在父结点增加新结点的指针；

所以, B*树分配新结点的概率比B+树要低, 空间使用率更高；

## 为什么MySQL的索引要使用B+树而不是B树?

两个角度: 范围查询和树的高度(IO查询次数)。

1. B+树在B树基础上进行变种, 非叶子节点用来做索引, 而叶子节点中有一个指针指向一下个叶子节点, 非常便于范围查询。
   1. 如果是多条的话, B树需要做**局部的中序遍历, 可能要跨层访问**。
   2. 而B+树由于所有数据都在叶子结点, 不用跨层, 同时由于有链表结构, 只需要找到首尾, 通过链表就能把所有数据取出来了。
2. B树不管叶子节点还是非叶子节点, 都会保存数据, 这样导致在非叶子节点中能保存的指针数量变少。指针少的情况下要保存大量数据, 只能增加树的高度, 导致IO操作变多, 查询性能变低。

## 为什么MySQL的索引要使用B+树而不是Hash索引?

如果只选一个数据, 那确实是hash更快。但是数据库中经常会选择多条, 这时候由于B+树索引有序, 并且又有链表相连, 它的查询效率比hash就快很多了。

而且数据库中的索引一般是在磁盘上, 数据量大的情况可能无法一次装入内存, B+树的设计可以允许数据分批加载, 同时树的高度较低, 提高查找效率。

## 总结

1. Hash索引可以快速进行等值查询, 时间复杂度为O(1), 但是并不适合范围查询和排序, 而且可能需要Hash碰撞, 极端情况下效率低。
2. 二叉查找树可以进行范围查询, 时间复杂度为O(log(n))效率也可以, 但是极端情况下会退化为线性链表, 最坏时间复杂度为O(n), 而且通常是基于主键插入数据, 退化概率很高, 性能低。
3. 平衡树中, 红黑树极端情况也会有右倾退化的问题(类似于链)；平衡二叉树绝对均衡, 查询效率很高, 但插入时需要频繁调整, 性能低。最重要的原因是: **平衡二叉树树比较高, 需要多次IO查询**。
4. B树每个节点可以存储更多的数据, 而且是多路, 可以大大降低树的高度, 减少了IO查询。但是范围查询时比较复杂, 效率略低。
5. B+树在B树基础上进行变种, 非叶子节点用来做索引, 而叶子节点中有一个指针指向一下个叶子节点, 非常便于范围查询。
6. B*树: 在B+树基础上, 为非叶子结点也增加链表指针, 将结点的最低利用率从1/2提高到2/3；

## 参看: 

- [为什么 MySQL 数据库要用B+树存储索引？——吴师兄学编程](https://www.cxyxiaowu.com/2440.html) (漫画形式一步步进行分析)
- [面试官:为什么MySQL的索引要用 B+ 树, 而不是B树？](https://www.zhihu.com/zvideo/1415976539947585536) (知乎小视频)
- [阿里面试: 分析为什么B+树更适合作为索引的结构以及索引原理——吴师兄学编程](https://www.cxyxiaowu.com/18067.html)
- [面试官: 为什么MySQL的索引要使用B+树, 而不是其它树？比如B树？](https://zhuanlan.zhihu.com/p/81273236) (从底层存储角度分析)

# MySQL的存储引擎有哪些, 及场景对比

## 背景

mysql的存储引擎也是面试中的常客了: 

> 面试官: 你了解的mysql存储引擎都有哪些？他们有什么区别, 以及使用场景是什么？
>
> 我: ……
>
> 面试官: 你能说说mysql存储引擎中的 InnoDB 和 MyISAM有什么区别吗？
>
> 我: ……

之前已经总结过了**InnoDB 和 MyISAM的区别和使用场景**, 但是面试中仅仅掌握这些好像还不够, 面试官更倾向于你对存储引擎了解的更多。所以这篇文章再来总结一番**mysql的存储引擎**。

## 存储引擎简介

存储引擎其实就是**对于数据库文件的一种存取机制**, 如何实现存储数据, 如何为存储的数据建立索引以及如何更新, 查询数据等技术实现的方法。

MySQL中的数据用各种不同的技术存储在文件(或内存)中, 这些技术中的每一种技术都使用不同的存储机制, 索引技巧, 锁定水平并且最终提供广泛的不同功能和能力。在MySQL中将这些不同的技术及配套的相关功能称为存储引擎。

## MySQL 中查看存储引擎

MySQL提供了查询存储引擎的功能, 执行以下sql即可查询到mysql中的存储引擎

```sql
SHOW
ENGINES;
```

mysql版本是8.0.12, 下面是在Navicat中执行的结果:

![mysql支持的存储引擎](images/MySQL%E6%80%BB%E7%BB%93/202109251451522.png)

其他命令: 

```mysql
# 查看mysql 默认的存储引擎
show variables like '% storage_engine';

# 查看具体某一个表所使用的存储引擎
show create table tablename;

#准确查看某个数据库中的某一表所使用的存储引擎
show table status from database where name = "tablename";
```

从上图中可以看出, mysql提供了9中存储引擎, 默认使用的是InnoDB。但是我们常用的一般也就是4中存储引擎, 分别是: InnoDB、MyISAM、MEMORY和ARCHIVE, 所以我们重点分析这4中存储引擎。

# MySQL 各种存储引擎分析

## InnoDB存储引擎

InnoDB是目前MYSQL的默认存储引擎, 是事务型数据库的首选引擎, 是目前最重要、使用最广泛的存储引擎。主要特性有: 

1. 提供了事务, 回滚以及系统崩溃修复能力和多版本迸发控制的事务的安全。
2. 支持自增长列(auto_increment)。
3. 支持外键(foreign key)。
4. 支持MVCC的行级锁。
5. 索引使用的是B+Tree。

**优点**: 提供了良好的事务处理、崩溃修复能力和并发控制。

**缺点**: 读写效率较差, 占用的数据空间相对较大。

**场景**: 既有读写也挺频繁, 请使用InnoDB。不知道如何选择时, 也可以选择InnoDB, 用以应对未来可能存在的复杂业务。

## MyISAM存储引擎

MyISAM 这种存储引擎不支持事务, 不支持行级锁, 只支持并发插入的表锁, 主要用于高负载的`select`。

**优点**: 占用空间小, 处理速度快。

**缺点**: 是不支持事务的完整性和并发性。

**场景**: 表中绝大多数都只是读查询(一般R/W > 100:1且update相对较少), 可以考虑 MyISAM

## MEMORY存储引擎

MEMORY存储引擎将表中的**数据存储到内存中**。

每个基于MEMORY存储引擎的表实际对应一个磁盘文件, 该文件的文件名和表名是相同的, 类型为.frm。该文件只存储表的结构, 而其数据文件, 都是存储在内存中, 这样有利于对数据的快速处理, 提高整个表的处理能力。

MEMORY存储引擎默认使用哈希(HASH)索引, 其速度比B+Tree要快, 如果希望使用B树型, 可在创建表的时候使用。

**优点**: 数据快速访问和处理。

**缺点**: 一旦发生异常, 重启或关闭机器, 数据都会丢失。

**场景**: 适合用于**查询的临时表**。

## ARCHIVE存储引擎

Archive是归档的意思, 在归档之后很多的高级功能就不再支持了, 仅仅支持最基本的插入和查询两种功能。

在MySQL 5.5版以前, Archive是不支持索引, 但是在MySQL 5.5以后的版本中就开始支持索引了。

Archive拥有很好的压缩机制, 它使用zlib压缩库, 拥有高效的插入速度。

**优点**: 高压缩, 快速插入。

**缺点**: 不适合频繁查询。

**场景**: **非常适合存储大量独立的、作为历史记录的数据**。例如: 非常适合作为日志表的存储引擎, 但是前提是不经常对该表进行查询操作。

## 四种常用的存储引擎如何选择

| 功 能        | InnoDB | MYISAM | Memory | Archive |
| ------------ | ------ | ------ | ------ | ------- |
| 存储限制     | 64TB   | 256TB  | RAM    | None    |
| 支持事务     | Yes    | No     | No     | No      |
| 支持全文索引 | No     | Yes    | No     | No      |
| 支持数索引   | Yes    | Yes    | Yes    | No      |
| 支持哈希索引 | No     | No     | Yes    | No      |
| 支持数据缓存 | Yes    | No     | N/A    | No      |
| 支持外键     | Yes    | No     | No     | No      |

## 其他不常用的存储引擎分析(了解即可)

### CSV存储引擎

使用该引擎的MySQL数据库表会在MySQL安装目录data文件夹中的和该表所在数据库名相同的目录中生成一个.CSV文件(所以, 它可以**将CSV类型的文件当做表进行处理**), 这种文件是一种普通文本文件, 每个数据行占用一个文本行。

该种类型的存储引擎不支持索引, 即使用该种类型的表没有主键列；另外也**不允许表中的字段为null**。csv的编码转换需要格外注意。

**场景**: 支持从数据库中拷入/拷出CSV文件。如果从电子表格软件输出一个CSV文件, 将其存放在MySQL服务器的数据目录中, 服务器就能够马上读取相关的CSV文件。同样, 如果写数据库到一个CSV表, 外部程序也可以立刻读取它。**
在实现某种类型的日志记录时, CSV表作为一种数据交换格式, 特别有用**。

### BLACKHOLE**存储引擎**(黑洞引擎)

支持事务, 而且支持MVCC的行级锁, **写入这种引擎表中的任何数据都会消失**, 主要用于做日志记录或同步归档的中继存储。

这个存储引擎除非有特别目的, 否则不适合使用。

像Unix系统下面的"`/dev/null`"设备一样, 不管我们写入任何信息, 都是有去无回, **那么BLACKHOLE存储引擎有什么用呢？**

> 在数据迁移过程中, 数据须要经过一个中转的MySQL服务器做一些相关的转换操作, 然后再通过复制移植到新的服务器上面。如果没有足够的空间来支持这个中转服务器的动作, 这时候就显示出BLACKHOLE的功效了, 他不会记录下任何数据, 但是会**在binlog中记录下所有的Query。而这些Query最终都会被复制利用, 并实施到最终的slave端**。

所以, 如果配置一主多从的话, 多个从服务器会在主服务器上分别开启自己相对应的线程, 执行binlogdump命令而且多个此类进程并不是共享的。为了避免因多个从服务器同时请求同样的事件而导致主机资源耗尽, 可以单独建立一个伪的从服务器或者叫分发服务器。

MySQL的用户手册上面介绍了BLACKHOLE存储引擎其他几项用途: 

- Query语法的验证;
- 测试二进制日志记录的性能开销, 如通过比较允许二进制日志功能的BLACKHOLE与禁止二进制日志功能的BLACKHOLE的性能来实现
- 查找与存储引擎自身不相关的性能瓶颈, 因为BLACKHOLE本质上是一个"no-op"的存储引擎

### PERFORMANCE_SCHEMA存储引擎

该引擎主要用于**收集数据库服务器性能参数**。

这种引擎提供以下功能: 提供进程等待的详细信息, 包括锁、互斥变量、文件信息；保存历史的事件汇总信息, 为提供MySQL服务器性能做出详细的判断；对于新增和删除监控事件点都非常容易, 并可以随意改变mysql服务器的监控周期, 例如(CYCLE、MICROSECOND)。

MySQL用户是不能创建存储引擎为PERFORMANCE_SCHEMA的表。

**场景**: 分析性能降低可能是由于哪些瓶颈。

### Federated存储引擎

该存储引擎可以不同的Mysql服务器联合起来, 逻辑上组成一个完整的数据库。这种存储引擎非常适合数据库分布式应用。

Federated存储引擎可以使你在本地数据库中访问远程数据库中的数据, 针对federated存储引擎表的查询会被发送到远程数据库的表上执行, 本地是不存储任何数据的。缺点: 

1. 对本地虚拟表的结构修改, 并不会修改远程表的结构

2. truncate 命令, 会清除远程表数据

3. drop命令只会删除虚拟表, 并不会删除远程表

4. 不支持 alter table 命令
5. `select count(*)`, `select * from limit M, N` 等语句执行效率非常低, 数据量较大时存在很严重的问题, 但是按主键或索引列查询, 则很快
6. 如果虚拟虚拟表中字段未建立索引, 而实体表中为此字段建立了索引, 此种情况下, 性能也相当差。但是当给虚拟表建立索引后, 性能恢复正常。
7. 类似 `where name like "str%" limit 1` 的查询, 即使在 name 列上创建了索引, 也会导致查询过慢, 是因为federated引擎会将所有满足条件的记录读取到本地, 再进行 limit 处理。

### MERGE存储引擎

MERGE存储引擎是一组MyISAM表的组合, 这些MyISAM表结构必须完全相同, 尽管其使用不如其它引擎突出, 但是在某些情况下非常有用。

场景: 对于服务器日志这种信息, 一般常用的存储策略是将数据分成很多表, 每个名称与特定的时间端相关。例如: 可以用12个相同的表来存储服务器日志数据, 每个表用对应各个月份的名字来命名。当有必要基于所有12个日志表的数据来生成报表, 这意味着需要编写并更新多表查询, 以反映这些表中的信息。与其编写这些可能出现错误的查询, 不如将这些表合并起来使用一条查询, 之后再删除Merge表, 而不影响原来的数据, 删除Merge表只是删除Merge表的定义, 对内部的表没有任何影响。

## 面试题: Mysql 中 MyISAM 和 InnoDB 的区别有哪些？

> - **InnoDB 支持事务, MyISAM 不支持事务**。
>   - 这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。
>   - 对于 InnoDB 每一条 SQL 语句都默认封装成事务进行提交, 这样就会影响速度, 优化速度的方式是将多条 SQL 语句放在 begin 和 commit 之间, 组成一个事务。
> - **InnoDB 支持外键, 而 MyISAM 不支持**。
>   - 对一个包含外键的 InnoDB 表转为 MYISAM 会失败。
> - **InnoDB 主键索引是聚集索引, 非主键索引是非聚集索引；MyISAM 都是是非聚集索引**。
>   - 聚簇索引的文件存放在主键索引的叶子节点上, 因此 InnoDB 必须要有主键, 通过主键索引效率很高。但是辅助索引需要两次查询, 先查询到主键, 然后再通过主键查询到数据。因此, 主键不应该过大, 因为主键太大, 其他索引也都会很大。
>   - MyISAM 是非聚集索引, 数据文件是分离的, 索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
> - **InnoDB 不保存表的具体行数**, 执行 `select count(*) from table` 时需要全表扫描。而**MyISAM 用一个变量保存了整个表的行数**, 执行上述语句时只需要读出该变量即可, 速度很快。
> - **InnoDB 最小的锁粒度是行锁, MyISAM 最小的锁粒度是表锁**。
>   - MyISAM 一个更新语句会锁住整张表, 导致其他查询和更新都会被阻塞, 因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
> - **存储结构不同**。
>   - MyISAM在磁盘上存储成三个文件, 数据和索引分离。
>   - InnoDB在磁盘上存储成两个文件, 数据和索引存储在一个文件。
> - **表的主键策略不同**。
>   - MyISAM: 允许没有任何索引和主键的表存在, 索引都是保存行的地址。
>   - InnoDB: 如果没有设定主键或者非空唯一索引, **就会自动生成一个6字节的主键(用户不可见)**, 数据是主索引的一部分, 附加索引保存的是主索引的值。
>

## 面试题: MySQL各种存储引擎的使用场景？

> mysql默认提供9中存储引擎:
>
> **InnoDB**
>
> 支持事务处理, 支持外键, 支持崩溃修复能力和并发控制。
>
> - 如果需要对事务的完整性要求比较高(比如银行), 要求实现并发控制(比如售票), 那选择InnoDB有很大的优势。
> - 如果需要频繁的更新、删除操作的数据库, 也可以选择InnoDB, 因为支持事务的提交(commit)和回滚(rollback)。
>
> **MyISAM**
>
> 插入数据快, 空间和内存使用比较低。如果数据表主要用来插入和查询记录, 则MyISAM引擎能提供较高的处理效率。
>
> - 表中绝大多数都只是读查询(一般R/W > 100:1且update相对较少), 可以考虑 MyISAM。
> - 如果对应用的完整性、并发性要求比较低, 也可以使用。
>
> **MEMORY**
>
> 所有的数据都在内存中, 数据的处理速度快, 但是安全性不高；它对表的大小有要求, 不能建立太大的表, 所以这类数据库只适用在相对较小的数据库表。
>
> - 如果需要**很快的读写速度, 对数据的安全性要求较低, 可以选择MEMOEY**。
> - 如果只是临时存放数据, 数据量不大, 并且不需要较高的数据安全性, 可以选择将数据保存在内存中的Memory引擎, 
>
> 例如在MySQL中使用该引擎作为临时表, 存放查询的中间结果。
>
> **ARCHIVE**
>
> - **非常适合存储大量独立的、作为历史记录的数据**。Archive非常适合存储归档数据。例如: 非常适合作为日志表的存储引擎, 但是前提是不经常对该表进行查询操作。
> - 如果只有INSERT和SELECT操作, 对数据的安全性要求较低, 可以选择Archive, Archive支持高并发的插入操作。
>
> **CSV**
>
> 使用该引擎的MySQL数据库表会在MySQL安装目录data文件夹中的和该表所在数据库名相同的目录中生成一个.CSV文件(所以, 它可以**将CSV类型的文件当做表进行处理**)。
>
> - 在实现某种类型的日志记录时, CSV表作为一种数据交换格式。
>
> **BLACKHOLE存储引擎(黑洞引擎)**
>
> 支持事务, 而且支持MVCC的行级锁, **写入这种引擎表中的任何数据都会消失**, 主要用于**一主多从的日志记录或同步归档的中继存储**。
>
> 
>
> **PERFORMANCE_SCHEMA存储引擎**
>
> **收集数据库服务器性能参数**。分析性能降低可能是由于哪些瓶颈。
>
> 注意, **同一个数据库也可以使用多种存储引擎的表**。如果一个表要求比较高的事务处理, 可以选择InnoDB。这个数据库中可以将查询要求比较高的表选择MyISAM存储。如果该数据库需要一个用于查询的临时表, 可以选择MEMORY存储引擎。
>

## 参看

- [mysql存储引擎](https://blog.csdn.net/yjclsx/article/details/81911027) (比较全面)
- [MySQL中常用存储引擎有哪些？它们相互之间有什么区别？](https://zhuanlan.zhihu.com/p/50564425)

- [BLACKHOLE存储引擎](http://www.djjwz.com/news/news3520.html) (介绍了BLACKHOLE**存储引擎**(黑洞引擎)的使用场景)

# MySQL的慢查询和数据库优化

## 数据库优化

[MySQL 对于千万级的大表要怎么优化？](https://www.zhihu.com/question/19719997/answer/81930332)

### mysql 单表多次查询和多表联合查询，哪个效率高?

![image-20210726210904393](images/MySQL%E6%80%BB%E7%BB%93/20210726210911.png)

单表查询有利于后期数据量大了分库分表，如果联合查询的话，一旦分库，原来的sql都需要改动

## 慢查询优化

首先开启慢查询日志，记录慢查询语句，然后分析SQL语句，看看是不是查询了多余的行，然后分析语句执行计划查看索引使用情况，之后修改语句或者修改索引，使语句尽可能命中索引，如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行分表。

通过explain查看sql语句的执行计划，通过执行计划来分析索引使用情况，只需要将explain添加在sql语句之前即可。

表中的索引：

![表中的索引](images/MySQL%E6%80%BB%E7%BB%93/20210626214501.png)

通过explain查看sql是否用到索引：

![explain查看sql的结果](images/MySQL%E6%80%BB%E7%BB%93/20210626214556.png)

- **type** 的信息很明显的体现是否用到索引，它提供了判断查询是否高效的重要依据依据，如const(主键索引或者唯一二级索引进行等值匹配的情况下)，ref(普通的⼆级索引列与常量进⾏等值匹配)，index(扫描全表索引的覆盖索引)
  。性能如下：`ALL < index < range ~ index_merge < ref < eq_ref < const < system`。 `ALL` 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.
  而 `index` 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快。

  一般情况下，得保证查询至少达到range级别，最好能达到ref

  ```sql
  --all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。
  explain select * from emp;
  
  --index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序
  explain  select empno from emp;
  
  --range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, <>, >, >=, <, <=, IS NULL, BETWEEN, LIKE, or IN() 
  explain select * from emp where empno between 7000 and 7500;
  
  --index_subquery：利用索引来关联子查询，不再扫描全表
  explain select * from emp where emp.job in (select job from t_job);
  
  --unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引
   explain select * from emp e where e.deptno in (select distinct deptno from dept);
   
  --index_merge：在查询过程中需要多个索引组合使用，没有模拟出来
  explain select * from rental where rental_date like '2005-05-26 07:12:2%' and inventory_id=3926 and customer_id=321\G
  
  --ref_or_null：对于某个字段即需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式
  explain select * from emp e where  e.mgr is null or e.mgr=7369;
  
  --ref：使用了非唯一性索引进行数据的查找
   create index idx_3 on emp(deptno);
   explain select * from emp e,dept d where e.deptno =d.deptno;
  
  --eq_ref ：使用唯一性索引进行数据查找
  explain select * from emp,emp2 where emp.empno = emp2.empno;
  
  --const：这个表至多有一个匹配行，
  explain select * from emp where empno = 7369;
   
  --system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现
  ```

- **select_type：**主要用来分辨查询的类型，是普通查询还是联合查询还是子查询

  ```sql
  --sample:简单的查询，不包含子查询和union
  explain select * from emp;
  
  --primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primary
  explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;
  
  --union:若第二个select出现在union之后，则被标记为union
  explain select * from emp where deptno = 10 union select * from emp where sal >2000;
  
  --dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响
  explain select * from emp e where e.empno  in ( select empno from emp where deptno = 10 union select empno from emp where sal >2000)
  
  --union result:从union表获取结果的select
  explain select * from emp where deptno = 10 union select * from emp where sal >2000;
  
  --subquery:在select或者where列表中包含子查询
  explain select * from emp where sal > (select avg(sal) from emp) ;
  
  --dependent subquery:subquery的子查询要受到外部表查询的影响
  explain select * from emp e where e.deptno in (select distinct deptno from dept);
  
  --DERIVED: from子句中出现的子查询，也叫做派生类，
  explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;
  
  --UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存
   explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size);
   
  --uncacheable union:表示union的查询结果不能被缓存：sql语句未验证
  ```

- table：每个查询对应的表名 。

  1、对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集 1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名

  2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表

  3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id

- **possible_key：**查询中可能用到的索引，一个或多个，查询涉及到的字段上若存在索引

- **key：**此字段是 MySQL 在当前查询时所真正使用到的索引。

- key_len：表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下长度越短越好。

- filtered：查询器预测满足下一次查询条件的百分比 。

- **rows:** 显示MySQL认为它执行查询时必须检查的行数。这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好。

- ref：显示索引的哪一列被使用了，如果可能的话，是一个常数

- extra：表示额外信息。

# MySQL的事务|隔离级别和MVCC原理

## 事务

### 什么是事务？

> 数据库事务指的是一组sql语句组成的数据库逻辑处理单元，在这组的sql操作中，要么全部执行成功，要么全部执行失败。

例子：转账。用户A要转账给用户B，要经历如下过程：用户A转账扣钱->用户B收账加钱，为了**保证数据的一致性**，要采用事务。两步操作都要成功才能成功，只要有一步出错，全都执行失败，即回滚。

### 事务的特性（ACID）

- 原子性（Atomicity）：事务的原子性操作，数据操作要么全部成功，要么全部失败。
  - 基于日志的`Redo/Undo`机制
- 一致性（Consistent）：事务执行前后的状态要一致，可理解为数据一致性。
- 隔离性（Isalotion）：事务之前相互隔离，不受影响，与事务的隔离级别密切相关。
  - 数据库系统提供-定的隔离机制，事务处理过程中的中间状态对外部是不可见的，保证事务在不受外部并发操作影响的“独立”环境执行。
- 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的（持久化到数据库），即使出现系统故障也能够保持。

原子性、隔离性、持久性都是为了保障一致性而存在的，一致性也是最终的目的。

### 什么是`Redo/Undo`机制？

Redo log用来记录某数据块被修改后的值，可以用来恢复事务已提交但还未持久化到数据库的数据；Undo log是用来记录数据更新前的值，保证数据更新失败能够回滚。

场景：假如某个时刻数据库崩溃，在崩溃之前有事务A和事务B在执行，事务A已经提交，而事务B还未提交。当数据库重启进行 crash-recovery 时，就会通过Redo log将已经提交事务的更改写到数据文件，而还没有提交的就通过Undo
log进行roll back。

### 什么是脏读？幻读？不可重复读？（事务可能导致的问题）

#### 脏读

脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。

**一个事务读到了另一个未提交事务修改的数据**。 回滚造成的影响。

#### 不可重复读

对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据**更新（`UPDATE`）**操作。

**一个事务修改了另一个未提交事务读取的数据**。 再次读取数据发生变更。

#### 幻读

幻读是针对数据**插入（`INSERT`）**
操作来说的。假设事务A修改了某些行的数据，但未提交，此时事务B插入了与事务A更改前记录相同的记录行，并先于事务A提交。那么在事务A查询时，会发现好像刚才更改对某些数据未起作用，但其实是事务B刚刚插入进来的，感觉除了幻觉，称之为幻读。

**一个事务根据搜索条件读出了一批数据，该事务未提交，但是另一个事务写入了（增删改）符合条件的记录，再次读取发现数据发生变更**。

#### 可重复读（正常情况）

可重复读指的是在同一个事务内，最开始读到的数据和事务结束前的任何时刻读到的同一批数据都是一致的。通常针对数据**更新（`UPDATE`）**操作。

### 事务隔离级别

#### 隔离级别解决的问题

事务隔离其实就是为了解决上面提到的脏读、不可重复读、幻读这几个问题。

| 隔离级别                     | 脏读   | 不可重复读 | 幻读   |
| ---------------------------- | ------ | ---------- | ------ |
| 读未提交（READ UNCOMMITTED） | 可能   | 可能       | 可能   |
| 读提交 （READ COMMITTED）    | 不可能 | 可能       | 可能   |
| 可重复读 （REPEATABLE READ） | 不可能 | 不可能     | 可能   |
| 串行化 （SERIALIZABLE）      | 不可能 | 不可能     | 不可能 |

从上往下，隔离强度逐渐增强，性能逐渐变差。采用哪种隔离级别要根据系统需求权衡决定，其中，**可重复读**是 MySQL 的默认级别。

#### 如何设置隔离级别

**查看当前数据库的隔离级别**：

```sql
#
查看事务隔离级别 5.7.20 之后
show variables like 'transaction_isolation';
SELECT @@transaction_isolation;

#
5.7.20 之前
SELECT @@tx_isolation;
show
variables like 'tx_isolation';

#结果
：
+---------------+-----------------+
| Variable_name | Value           |
+---------------+-----------------+
| tx_isolation  | REPEATABLE-READ |
+---------------+-----------------+
```

**查询当前有多少事务正在运行**：

```mysql
select *
from information_schema.innodb_trx;
```

**修改数据库的隔离级别**：

```sql
set
[作用域] transaction isolation level [事务隔离级别]
，
SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE}
```

- 作用域中GLOBAL 是全局的，而 SESSION 只针对当前回话窗口。
- 隔离级别是 {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} 这四种，不区分大小写。

例子：比如下面这个语句的意思是设置全局隔离级别为读提交级别。

```mysql
set global transaction isolation level read committed;
```

#### 隔离级别分析

建立一张表用来测试

```mysql
CREATE TABLE `user`
(
    `id`   int(11) NOT NULL AUTO_INCREMENT,
    `name` varchar(30) DEFAULT NULL,
    `age`  tinyint(4)  DEFAULT NULL,
    PRIMARY KEY (`id`)
) ENGINE = InnoDB
  AUTO_INCREMENT = 2
  DEFAULT CHARSET = utf8mb4
```

初始只有一条记录：

![初始user表数据](images/MySQL%E6%80%BB%E7%BB%93/20210627173121.png)

##### 读未提交

MySQL 事务隔离其实是依靠锁来实现的，加锁自然会带来性能的损失。而读未提交隔离级别是不加锁的，所以它的性能是最好的，没有加锁、解锁带来的性能开销。但有利就有弊，这基本上就相当于裸奔啊，所以它连脏读的问题都没办法解决。

任何事务对数据的修改都会第一时间暴露给其他事务，即使事务还没有提交。

做一个实验，先将全局隔离级别设置为**读未提交**：

```mysql
set global transaction isolation level read uncommitted;
```

设置完成后，只对之后新起的 session 才起作用，对已经启动 session 无效。如果用 shell 客户端那就要重新连接 MySQL，如果用 Navicat 那就要创建新的查询窗口。这时候再重新启动两个黑窗口进行模拟。

Mysql中开启事务有两种方式`begin/start transaction`，最后提交事务执行commit，或者回滚事务rollback。在执行`begin/start transaction`
命令，它们并不是一个事务的起点，在执行完它们后的第一个sql语句，才表示事务真正的启动 。

**分析执行流程**：

1、在第一个黑窗口（事务A）中，执行`begin；`后；将`id=1`的数据行改为`name='duktig666'`。

```mysql
begin;
UPDATE user
SET name='duktig666'
WHERE id = 2;
```

2、在第二个黑窗口（事务B）中，执行执行`begin；`后；执行查询，观察数据。

```
begin;
SELECT * FROM user;
```

3、在第一个黑窗口（事务A）中将事务回滚，在第二个黑窗口（事务B）中再次执行查询，观察数据。

```mysql
rollback;
```

```
SELECT * FROM user;commit;
```

![读未提交分析](images/MySQL%E6%80%BB%E7%BB%93/20210627180646.png)

**总结**：

**读未提交，其实就是可以读到其他事务未提交的数据，但没有办法保证你读到的数据最终一定是提交后的数据，如果中间发生回滚，那就会出现脏数据问题，读未提交没办法解决脏数据问题。更别提可重复读和幻读了，想都不要想。**

##### 读提交

既然读未提交没办法解决脏数据问题，那么就有了读提交。

**读提交就是一个事务只能读到其他事务已经提交过的数据，也就是其他事务调用 commit 命令之后的数据**。那脏数据问题迎刃而解了。

读提交事务隔离级别是大多数流行数据库的默认事务隔离界别，比如 Oracle，但是不是 MySQL 的默认隔离界别。

继续验证，将事务隔离级别设置为**读提交**，然后重新打开两个mysql黑窗口。

```mysql
set global transaction isolation level read committed;
```

**分析执行流程**：

1、事务A开启事务，执行修改操作修改id=2的name：duktig->duktig666。

2、此时事务A未提交，事务B开启事务，执行查询操作，数据为duktig。

3、事务A提交，事务B再次执行查询操作，数据为duktig666。

具体代码参看“读未提交都差不多”。

![读提交分析](images/MySQL%E6%80%BB%E7%BB%93/20210627184016.png)

在不同的时刻，查询出来的数据可能是不一致的，可能会受到其他事务的影响。

**总结**：

读提交解决了脏读的问题，但是无法做到可重复读，也没办法解决幻读。

##### 可重复读

可重复是对比不可重复而言的，上面说不可重复读是指同一事务不同时刻读到的数据值可能不一致。

**可重复读是指，事务不会读到其他事务对已有数据的修改，即使其他事务已提交，也就是说，事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。但是，对于其他事务新插入的数据是可以读到的，这也就引发了幻读问题**。

继续验证，需改全局隔离级别为可重复读级别，**将name重置为duktig**，并重新打开两个黑窗口。

```mysql
set global transaction isolation level repeatable read;
```

可对读提交的流程再执行一次，发现修改操作不会出现可重复读，即解决了可重复读（上述操作不在重复验证）。但是更新操作又引起了数据不一致（幻读）。

**分析验证流程**：

1、开启事务A，执行修改操作修改id=2的name：duktig->duktig666。

2、开启事务B，在事务A执行完update后，执行insert操作，插入记录“`name='duktig' age=23`”（这条数据和事务A修改前的name和age的值相同）。

```mysql
INSERT INTO user (name, age)
VALUES ('duktig', 23);
```

3、事务B提交后，事务A执行select操作，查询`age=23`的数据，这时出现了多一行的数据，这是事务B刚刚插入的，即幻读。

![可重复读分析](images/MySQL%E6%80%BB%E7%BB%93/20210627190808.png)

看到有文章提到，在Mysql中，默认的不可重复读个隔离级别也解决了幻读的问题。但是我这确实出现了幻读问题，这需要再分析分析。

##### 串行化

串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束。

### MVCC原理

#### 版本链

InnoDB聚簇索引的两个必要隐藏列：

1. `trx_id`：一个事务每次对某条聚簇索引改动时，会把改事务的id赋值给`trx_id`。
2. `roll_pointer`：每次对某条聚簇索引改动时，会将旧版本写到undo日志中。这个隐藏列相当于一个指针，可以通过它找到该记录修改前的信息。（Insert操作的undo日志没有该属性，insert
   undo只在事务回滚时发挥作用，事务提交后就没用了。

版本链：每次更新记录，旧值放到undo日志，根据`roll_pointer`连成一条版本链，头节点是当前记录的最新值。另外还包含每个版本对应的事务id。

**通过版本链来控制并发事务访问相同记录时的行为**，称这种机制为多版本并发控制。

#### ReadView

读未提交直接读最新的版本就好了，但是**读提交和可重复读都必须保证读到已提交的事务修改过的记录**，即另一个事务已经修改了记录但是未提交，则不能读取最新版的记录。

**核心问题：需要判断版本链中的哪个版本是当前事务可见的**。

ReadView的四个重要内容：

1. `m_ids`：在生成ReadView时，当前系统活跃读写事务的事务id列表。
2. `min_trx_id`：在生成ReadView时，当前系统活跃读写事务的最小事务id；也就是`m_ids`中的最小值。
3. `max_trx_id`：在生成ReadView时，系统应该分配给下一个事务的id值。
4. `creator_trx_id`：生成该ReadView的事务的事务id。只有执行insert、update、delete操作时才会分配事务id，否则该值默认为0。

**如何判断版本可见？**

1. 访问版本的trx_id与creator_trx_id相同（事务访问自己的版本），可以访问该版本。
2. 访问版本的trx_id小于min_trx_id，表明生成该版本的事务在当前事务生成ReadView之前已提交，可以访问。
3. 访问版本的trx_id大于max_trx_id，不可访问。
4. trx_id在min_trx_id和max_trx_id之间，需要判断trx_id是否在m_ids中，用以确定是否访问。在，则不能访问。

**读提交和可重复读生成ReadView的时机：**

- 读提交：每次读取数据前都生成一个ReadView。
- 可重复读：在第一次读取数据时生成ReadView。

#### 二次索引与MVCC

只有在聚簇索引中才有 `trx_id` 和 `roll_pointer` 隐藏列，那么**二级索引（非聚簇索引）如何判断可见性呢**？

1. 二级索引页面的Page Header部分，有一个属性 `PAGE_MAX_TRX_ID`，执行增删改查时，如果执行操作的事务id大于`PAGE_MAX_TRX_ID`
   的值，则将其值设置为执行操作的事务id。即 **`PAGE_MAX_TRX_ID` 代表修改该二级索引页面最大的事务id**。
2. 执行select时，如果ReadView的 `min_trx_id` 大于 `PAGE_MAX_TRX_ID`，则说明该页面的值对ReadView可见；如果小于，则需要回表进行判断。
3. 利用二级索引中的主键进行回表操作，得到聚簇索引的记录后，再按照聚簇索引的方式从第一个版本开始，依次判断可见性。

#### 可重复读是否能解决幻读问题？

mysql的可重复读在MVCC和锁机制下尽可能保证幻读问题，但是并不能完全禁止幻读。

特殊情况下，仍然可能出现幻读问题：

- T1执行SELECT生成ReadView
- T2新插入一条记录，并且提交。
- **ReadView不能阻止T1执行UPDATE或者DELETE语句来改动这条新插入的记录**。（由于T2提交，改动这条记录并不能造成阻塞）
- T1修改这条记录，这条记录的trx_id变成了T1的id。
- 之后T1再次查询时，在查询结果中就可以发现这条记录了。

参考：

- [我以为我对Mysql事务很熟，直到我遇到了阿里面试官](https://zhuanlan.zhihu.com/p/148035779)
- [MySQL事务隔离级别和实现原理（看这一篇文章就够了！）](https://zhuanlan.zhihu.com/p/117476959)
- [面试官:谈谈你对mysql事务的认识?](https://zhuanlan.zhihu.com/p/166158027)
- [MySQL 聊聊MySQL锁机制及事务](

# MySQL锁机制

本篇文章提到的锁，如果没有特别说明，默认指InnoDB的锁。

## MySQL加锁的目的是什么？

数据库的锁是为了解决事务的隔离性问题，为了让事务之间相互不影响，每个事务进行操作的时候都会对数据加上一把特有的锁，防止其他事务同时操作数据。

## MySQL的锁是基于什么实现的？

数据库里面的锁是基于索引实现的，在Innodb中我们的锁都是作用在索引上面的，当我们的SQL命中索引时，那么锁住的就是命中条件内的索引节点(行锁)，如果没有命中索引的话，那我们锁的就是整个索引树（表锁）。

## 解决并发事务问题的方式

### 写写情况

任何一种隔离级别都不允许出现脏写现象，是通过加锁来实现的。锁结构两个比较重要的属性：

- trx信息：表示锁结构与哪个事务有关。
- is_waiting：表示当前事务是否在等待。

锁获取的状态：

- 获取锁成功：内存中生成了对应的锁结构，而且is_waiting的值为false。（除了隐式锁）
- 获取锁失败：内存中生成了对应的锁结构，而且is_waiting的值为true，事务需要等待。
- 不加锁：内存中没有生成锁结构，可以直接操作。（不包括隐式锁）

释放锁：释放锁，发现还有事务等待锁，修改对应锁结构is_waiting的值为true。

### 读写或写读情况

**方案1：读操作使用MVCC，写操作加锁**

MVCC通过ReadView找到符合条件的记录版本，**查询语句只能读到在生成ReadView之前已经提交的事务所做的更改**，在生成ReadView之前未提交或者之后才开启的事务所做的修改操作是看不到的。

写操作针对最新版本的记录，读记录的历史版本和改动记录的最新版本是不冲突的。

方案2：读写操作都加锁

### 一致性读

事务利用MVCC方式，读写操作不冲突称之为一致性读。

一致性读并不会对表中的任何记录进行加锁，其他事务可以自由对表中的记录进行改动。

### 锁定读

对记录加S锁：`SELECT …… LOCK IN SHARE MODE`

对记录加X锁：`SELECT …… FOR UPDATE`

### 写操作

#### DELETE

1. 先在B+树中定位到记录，然后获取X锁，最后执行 delete mark 操作（添加删除标记）

#### UPDATE

- **未修改主键值，并且被更新的列所占用的存储空间未改变**：定位到B+树的记录位置，获取X锁，修改值。
- **未修改主键值，并且被更新的列至少有一个所占用的存储空间改变**：定位到B+树的记录位置，获取X锁，彻底删除记录（而不是delete mark），然后再新增记录。
- **修改记录的键值**：定位到B+树的记录位置，获取X锁，执行DELETE操作，然后再执行INSERT操作。

#### INSERT

一般情况下，新插入记录受隐式锁保护，不生成对应的锁结构。

## 锁的内存结构

### 基本介绍

“锁”本质上是内存中的结构，在事务执行之前是没有锁的（也就是说一开始是没有锁结构与记录进行关联的）。

当一个事务相对这条记录进行改动时，首先会看内存中有没有与这条记录相关联的锁结构；如果没有，就在内存中生成一个锁结构与记录相关联。

锁结构有很多信息，**比较重要的属性如下**：

- `trx`信息：表示这个锁结构与哪个事务相关联。
- `is_waiting`：表示当前事务是否在等待。
- `type`：表示锁的类型。

### **锁结构的变化：**

1. 事务T1修改记录前，生成锁结构（因为之前没有别的事务为这条记录加锁）：`trx:T1  is_waiting:false`。称这个操作为加锁成功。
2. 事务T1提交前，事务T2也想修改这条记录。在内存中发现有一个锁记录，T2也生成一个所记录`trx:T2  is_waiting:true`，表示需要等待，称为加锁失败。
3. 事务T1提交后，就会把它生成的锁机构释放掉，然后检测一次是否还有与这条记录相关联的锁结构。发现事务T2在等待获取锁，所以把事务T2的 `is_waiting:true` 改为 `false`
   ，然后把该事物对应的线程唤醒，让T2继续执行。此时T2就获取到锁了。

### 哪些记录可以放在一个锁结构中？

上文提到：对一条记录加锁的本质是在内存中创建一个锁结构与之关联（隐式锁除外）。

但是一个事务对多条记录加锁，是不是要创建多个锁结构？如果加锁记录太多，岂不是造成了内存占用太大。

所以，如果符合以下条件，这些记录的锁可以放到一个锁结构中：

1. 在同一个事务中进行加锁操作
2. 被加锁的记录在同一个页面中
3. 加锁的类型是一样的
4. 等待状态是一样的

### 锁结构详解

<img src="images/MySQL%E6%80%BB%E7%BB%93/202203022325296.jpg" alt="271a340123d72197fd99faa32c1190b" style="zoom:67%;" />

- 锁所在事务信息和索引信息 在内存结构中是一个指针，不会占用太大空间
- 表锁/行锁信息：
  - 表锁记载着这是对哪个表加的锁
  - 行锁记载下面3个重要信息：
    - Space ID：记录所在的表空间
    - Page Number：记录所在的页号
    - n_bits：对于行锁来说，一条记录对用一个比特。用以区分哪些记录被加了行锁，n_bits为了让页面插入新记录时不至于重新分配锁结构，一般来说会比页面记录多一些。
- type_mode：是一个32比特的数，分为 lock_mode、lock_type、rec_lock_type
  三部分。![91bb6399110c93e44260472028a69fc](images/MySQL%E6%80%BB%E7%BB%93/202203022332392.jpg)
    - lock_mode（锁模式）占用4比特，具体如下：
      - LOCK_IS（十进制0）
      - LOCK_IX（十进制1）
      - LOCK_S（十进制2）
      - LOCK_X（十进制3）
      - LOCK_AUTO_INC（十进制4）
    - lock_type（锁类型）占5~8位，现阶段只用了第5位和第6位
      - LOCK_TABLE（十进制16）：第5位为1，表级锁
      - LOCK_REC（十进制32）：第6位为1，行级锁
    - rec_lock_type（行锁的具体类型），只有在lock_type值为LOCK_REC时，才会细分更多的类型
      - LOCK_ORDINARY（十进制0）：表示next-key锁（临键锁）
      - LOCK_GAP（十进制512）：第10比特位为1，表示gap（间隙）锁
      - LOCK_REC_NOT_GAP（十进制1024）：第11比特位为1，表示记录锁
      - LOCK_INSERT_INTENTION（十进制2048）：第12比特位为1，表示插入意向锁
      - 其他类型
      - LOCK_WAIT（十进制256）：第9比特位为1，is_waiting表示为true。
    - 一堆比特位：每个比特位，表示锁结构对应一条记录。

## 锁的分类

基于锁的属性分类：共享锁、排他锁。

基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁、自增锁。

基于锁的状态分类：意向共享锁、意向排它锁。

基于加锁的态度分类：悲观锁、乐观锁。

## 共享锁和排它锁（读写锁）

### 共享锁

**共享锁**又称读锁，简称S锁；当一个事务为数据加上读锁之后，**其他事务只能对该数据加读锁，而不能对数据加写锁**，直到所有的读锁释放之后其他事务才能对其进行加持写锁。

共享锁的特性主要是为了支持并发的读取数据，读取数据的时候不支持修改，避免出现重复读的问题。

![共享锁](images/MySQL%E6%80%BB%E7%BB%93/202111051714836.png)

### 排它锁

排他锁又称写锁，简称X锁；当一个事务为数据加上写锁时，其他请求将不能再为数据加任何锁，直到该锁释放之后，其他事务才能对数据进行加锁。

排他锁的目的是在数据修改时候，不允许其他人同时修改，也不允许其他人读取。避免了出现脏数据和脏读的问题。

![排它锁](images/MySQL%E6%80%BB%E7%BB%93/202111051729003.png)

## 读写意向锁

意向锁也是表级锁，也可分为读意向锁（IS 锁）和写意向锁（IX 锁）。分为如下情况：

- 某条记录加S锁时，需要先在表级别加IS锁。
- 某条记录加X锁时，需要先在表级别加IX锁。
- 加表级别S锁时，此表不能加有IX锁。
- 加表级别X锁时，此表不能加有IS、IX锁。

意向锁是为了，在加表级别S、X锁时，快速判断表中记录是否被上锁，避免遍历该表的所有记录。

## 表锁

### 什么是表锁？

**表锁**是指上锁的时候锁住的是整个表，当下一个事务访问该表的时候，必须等前一个事务释放了锁才能进行对表进行访问；

表锁由 MySQL Server 实现，一般在执行 DDL 语句时会对整个表进行加锁，比如说 ALTER TABLE 等操作。

表锁的特点： **粒度大，加锁简单，容易冲突**。

### 显式加表锁

在执行 SQL 语句时，也可以明确指定对某个表进行加锁：

```sql
#
分为读锁和写锁
lock table user read(write); 
#
成功
select *
from user
where id = 100;
#
失败
，未提前获取该 role的读表锁
select *
from role
where id = 100;
#
失败
，未提前获得user的写表锁
update user
set name = 'Tom'
where id = 100;
#
显示释放表锁
unlock tables; 
```

表锁使用的是一次性锁技术，也就是说，在会话开始的地方使用 lock 命令将后续需要用到的表都加上锁，在表释放前，只能访问这些加锁的表，不能访问其他表，直到最后通过 unlock tables 释放所有表锁。

### **什么时候释放表锁**？

- 使用 `unlock tables` 显示释放锁
- 会话持有其他表锁时执行 `lock table` 语句会释放会话之前持有的锁
- 会话持有其他表锁时执行 `start transaction` 或者 `begin` 开启事务时，也会释放之前持有的锁。

### 表级别的S锁、X锁

表级别的锁一般用在执行 `ALTER TABLE` 或 `DROP TABLE`的DDL语句时，然后再执行增删改查时会阻塞。

### 表级别的IS锁、IX锁

参看上述的读写意向锁

### 表级别的AUTO-INC锁

AUTO-INC 锁又叫自增锁（一般简写成 AI 锁），是一种表锁，当表中有自增列（AUTO_INCREMENT）时出现。

主要实现方式有两种：

1. **采用AUTO-INC锁**。执行插入语句时，加一个表级别的AUTO-INC锁，然后为每条待插入记录的AUTO_INCREMENT列分配递增的值，插入执行完毕，锁释放。
2. **采用一种轻量级的锁**（mutex，MySQL 从 5.1.22 版本开始引入）。生成自增值后释放，而不是要等插入完成才释放锁。

`innodb_autoinc_lock_mode`来控制使用哪种锁：

- 值为0，一律使用AUTO-INC锁
- 值为1，插入数量确定使用轻量级锁，不确定使用AUTO-INC锁
- 值为2，一律使用轻量级锁（不同事务自增列值交叉，主从复制不安全）

**注意事项：**

当插入表中有自增列时，数据库需要自动生成自增值，它会**先为该表加 AUTOINC 表锁，阻塞其他事务的插入操作，这样保证生成的自增值肯定是唯一的**。

AUTOINC 锁具有如下特点：

- AUTO_INC 锁互不兼容，也就是说同一张表同时只允许有一个自增锁；
- 自增值一旦分配了就会 +1，如果**事务回滚，自增值也不会减回去**，所以自增值可能会出现中断的情况。

## 行锁

### 什么是行锁？

行锁是指上锁的时候锁住的是表的某一行或多行记录，其他事务访问同一张表时，只有被锁住的记录不能访问，其他的记录可正常访问；

不同存储引擎的行锁实现不同。

特点：**粒度小，加锁比表锁麻烦，不容易冲突，相比表锁支持的并发要高**；

### 行锁的原理

行锁的原理和索引有关。

InnoDB 是聚簇索引，也就是 B+树的叶节点既存储了主键索引也存储了数据行。而 InnoDB 的二级索引的叶节点存储的则是主键值，所以通过二级索引查询数据时，还需要拿对应的主键去聚簇索引中再次进行查询。

**单行记录行锁原理**

下面以两条 SQL 的执行为例，讲解一下 InnoDB 对于单行数据的加锁原理。

```sql
#
聚簇索引执行修改
update user
set age = 10
where id = 49;
#
二级索引执行修改
update user
set age = 10
where name = 'Tom';
```

第一条 SQL 使用主键索引来查询，则只需要在 id = 49 这个主键索引上加上写锁；

第二条 SQL 则使用二级索引来查询，则首先在 name = Tom 这个索引上加写锁，然后由于使用 InnoDB 二级索引还需再次根据主键索引查询，所以还需要在 id = 49 这个主键索引上加写锁。

**多行记录行锁原理**

```sql
update user
set age = 10
where id > 49;
```

MySQL Server 会根据 WHERE 条件读取第一条满足条件的记录，然后 InnoDB 引擎会将第一条记录返回并加锁，接着 MySQL Server 发起更新改行记录的 UPDATE
请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有匹配的记录为止。

当然这中间还有很多的优化，就不细细阐述了。

### 行锁的类型

根据锁的粒度可以把锁细分为表锁和行锁，行锁根据场景的不同又可以进一步细分，依次为 Next-Key Lock，Gap Lock 间隙锁，Record Lock 记录锁和插入意向 GAP 锁。

不同的锁锁定的位置是不同的，比如说记录锁只锁住对应的记录，而间隙锁锁住记录和记录之间的间隔，Next-Key Lock 则所属记录和记录之前的间隙。

![行锁的范围](images/MySQL%E6%80%BB%E7%BB%93/202111051714635.png)

### 记录锁（Record Lock）

**记录锁**：事务在加锁后锁住的只是表的某一条记录。(官方命名LOCK_REC_NOT_GAP)

**大致触发条件：**

- 精准条件命中，并且命中的条件字段是唯一索引。
  - **例如：**`update user_info set name=’张三’ where id=1`     ，这里的id是唯一索引。
- 当 SQL 语句无法使用索引时，会进行全表扫描，这个时候 MySQL 会给整张表的所有数据行加记录锁，再由 MySQL Server 层进行过滤。但是，在 MySQL Server 层进行过滤的时候，如果发现不满足 WHERE
  条件，会释放对应记录的锁。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。

所以更新操作必须要根据索引进行操作，没有索引时，不仅会消耗大量的锁资源，增加数据库的开销，还会极大的降低了数据库的并发性能。

**记录锁的作用：**加了记录锁之后数据可以**避免数据在查询的时候被修改的重复读问题**，**也避免了在修改的事务未提交前被其他事务读取的脏读问题**。

### **间隙锁（Gap Lock）**

**间隙锁**：在事务加锁后其锁住的是表记录的某一个区间，当表的相邻ID之间出现空隙则会形成一个区间，遵循**左开右闭**原则。

比如下面的表里面的数据ID 为 1,4,5,7,10 ,那么会形成以下几个间隙区间，-n-1区间，1-4区间，7-10区间，10-n区间 （-n代表负无穷大，n代表正无穷大）

![间隙锁](images/MySQL%E6%80%BB%E7%BB%93/202111051721479.png)

**大致触发条件：**范围查询并且查询未命中记录，查询条件必须命中索引、间隙锁只会出现在REPEATABLE_READ（重复读)的事务级别中。

**例如**：对应上图的表执行 `select * from user_info where id>1 and id<4` (这里的id是唯一索引) ，这个SQL查询不到对应的记录，那么此时会使用间隙锁。

注意事项：

- `Infimum`：表示页面最小记录
- `Supremum`：表示页面最大记录

**间隙锁作用**：**防止幻读问题**。

### **临键锁(Next-Key Lock)**

临键锁：**是INNODB的行锁默认算法**，总结来说它就是记录锁和间隙锁的组合，**临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住**。

**例如：**下面表的数据执行 `select * from user_info where id>1 and id<=13 for update ;`

会锁住ID为 1,5,10的记录；同时会锁住，1至5,5至10,10至15的区间。

![img](images/MySQL%E6%80%BB%E7%BB%93/v2-8c9555f753fbab98c71760ddba9e5068_720w.png)

**大致触发条件：**范围查询并命中，查询命中了索引。

**临键锁的作用：**结合记录锁和间隙锁的特性，**临键锁避免了在范围查询时出现脏读、重复读、幻读问题**。加了临键锁之后，在范围区间内数据不允许被修改和插入。

### 插入意向锁（LOCK_INSERT_INTENTION）

插入意向锁是一种特殊的间隙锁（Insert Intention Lock）表示插入的意向，只有在 INSERT 的时候才会有这个锁。

一个事务插入一条记录，需要判断插入位置是否被别的事务加了gap锁（包含next-key锁）。如果有的话，插入操作需要等待，直到加gap锁的事务提交。

### 隐式锁

一般执行Insert不需要在内存中生成锁结构（当然如果插入的间隙被其他事务加了gap锁，那么本次Insert操作会阻塞，当前事务会在间隙插入意向锁）。

但这样可能会出现问题。举例，先插入一条记录（无关联锁结构），然后如下情况：

- 立即使用`SELECT …… LOCK IN SHARE MODE` 或 `SELECT …… FOR UPDATE`，进行锁定读，获取锁。如果允许，那么出现脏读怎么办？
- 立即修改这条记录（获取锁），怎么办？

这些情况下，事务id要起作用了

-

对于聚簇索引：trx_id是一个隐藏列，记录最后改动的事务id。新插入记录，trx_id为当前事务的id，如果想加锁，会看trx_id是否是活跃事务。如果不是，正常获取；如果是，帮助当前事务建立X锁的锁结构，is_writing为false。然后自己也创建一个锁结构，is_writing为true，进入等待状态。

- 对于二级索引： 二级索引页面的Page Header的PAGE_MAX_TRX_ID记录改动最大的事务id。如果PAGE_MAX_TRX_ID小于当前最小活跃事务id，表明已提交，否则需要定位的聚簇索引，然后执行上述的操作。

所以，一个事务新插入记录可以不显示加锁，这个事务id相当于加了一个隐式锁。别的事务加锁，由于隐式锁存在，会给当前事务生成一个锁结构，然后给自己也生成锁结构，并且进入等待状态。

**隐式锁作用：延迟生成锁结构。如果事务执行不需要获取与该隐式锁相冲突的锁，可以避免建立锁结构。**

特殊情况：

1. 插入时遇到重复键会报错，但在报错前会加锁
   1. 主键（聚簇索引）重复，读提交下加记录锁，可重复读下加临键锁
   2. 二级唯一索引重复，加临键锁。
2. 外键检查
   1. 待查记录在外键表中可以找到，父表给该记录加记录锁
   2. 找不到时，读提交不加锁，可重复读加gap锁。

## 加锁语句分析

### 普通SELECT语句

在不同隔离级别下，普通的SELECT语句具有不同的表现：

- 在 读未提交 隔离级别下，不加锁，直接读取记录的最新版本；可能出现脏读、不可重复读和幻读现象。
- 在 读已提交 隔离级别下，不加锁；在每次执行普通SELECT语句的时候会生成一个ReadView；这样避免了脏读现象，但是没有避免不可重复读和幻读现象。
- 在 可重复读
  隔离级别下，不加锁；只在第一次执行普通SELECT语句时生成一个ReadView，这样可以避免脏读和不可重复读，不能完全避免幻读问题（存在特殊情况：事务T1查询出10条记录，事务未提交；事务T2，插入一条记录，提交；事务T1修改了刚刚事务T2插入的记录，那么再次查询时，事务T1会查询出11条数据）。
- 在 串行化 隔离级别下，分为两种情况：
  - 系统变量 `autocommit=0`时（禁用自动提交），普通的SELECT查询会转换为`SELECT …… LOCK IN SHARE MODE` 这样的语句。也就是在读记录前需要先获取记录的S锁。具体加锁情况与 可重复读
    情况下一样。
  - 系统变量`autocommit=1`时，普通SELECT语句不加锁，只是利用MVCC生成一个ReadView读取记录。为什么呢？因为启动自动提交，意味着一个事务只包含一条语句，而执行一条语句不会出现不可重复读、幻读这样的现象。

### 锁定读的语句

#### 锁定读的语句

- 语句1：`SELECT …… LOCK IN SHARE MODE;`
- 语句2：`SELECT …… FOR UPDATE;`
- 语句3：`UPDATE ……`
- 语句4：`DELETC ……`

语句1和2是MySQL中规定的两种锁定读的语法格式，而语句3和4在执行中需要先定位到被改动的记录并给记录加锁，因此也可以任务是锁定读。

在了解锁定读语句加锁之前，引入两个概念：匹配模式和唯一性搜索。

#### 匹配模式

使用索引执行查询时，查询优化器首先会生成若干个扫描区间。针对每个扫描区间，可以快速定位到第一条记录，然后沿着这条记录所在的单链表可以扫描这个区间的其他记录，直到某条记录不在这个区间为止。如果被扫描的区间是一个单节点扫描区间，可以说此时的匹配模式是 **
精确匹配**。

举例：联合索引idx_a_b(a,b)，

- 边界条件时 `a=1`，扫描区间为[1,1]，是单节点扫描区间，属于精确匹配。
- 边界条件时 `a=1 AND b=1`，扫描区间为[(1,1),(1,1)]，是单节点扫描区间，属于精确匹配。
- 边界条件时 `a=1 AND b>=1`，扫描区间为[(1,1),(1,+∞)]，是单节点扫描区间，属于精确匹配。

#### 唯一性搜索

如果扫描之前，事先知道扫描区间最多包含一条记录，把这种情况称为 **唯一性搜索**。

怎么确定最多只包含一条记录：

- 匹配模式为精确匹配
- 使用的索引是主键或是唯一二级索引；如果使用的是唯一二级索引，搜索条件不能是`索引列 IS NULL`的形式（因为对一唯一二级索引列来说，可以存储多个值为NULL的记录）
- 如果索引中包含多个列，那么在生成扫描区间时，每一个都得被用到

#### 影响语句加锁的因素

- 事务的隔离级别
- 语句执行时使用的索引类型
- 是否是精确匹配
- 是否是唯一性搜索
- 具体的语句类型（SELECT、UPDATE、INSERT、FELETE）

#### 读取某个扫描区间中记录的加锁过程

**读取某个扫描区间的记录加锁情况如下：**

步骤1：首先快速地在B+树叶子节点中定位到该扫描区间中的第一条记录，把该记录作为当前记录。

步骤2：为当前记录加锁。

一般情况下，对于锁定读的语句，在隔离级别不大于 **读提交** 时，会为当前记录加记录锁。在隔离级别不小于 **可重复读** 时，会为记录加临键锁。

步骤3：判断索引下推的条件是否成立。

**索引下推，是来把查询中与被使用索引有关的搜索条件下推的存储引擎中判断，而不是返回server层再判断**。索引下推只是为了减少回表次数，只适用于二级索引和SELECT语句。

符合索引下推条件，跳到第四步继续执行；不符合获取当前记录的单链表的下一条记录，将该记录作为新的当前记录，跳回步骤二。另外步骤3还会判断当前记录是否符合形成扫描区间的边界条件，不符合跳过步骤4和步骤5，直接向server发送“查询完毕”的信息。

需注意，**步骤3不会释放锁**。

步骤4：执行回表操作。

二级索引回表，查到聚簇索引并给该记录加记录锁。

步骤5：判断边界条件是否成立。

符合边界条件，继续执行步骤6；否则在隔离级别不大于读提交时，释放该记录锁，并向server层返回“查询完毕”的信息。

步骤6：server层判断其余搜索条件是否成立。

如果成立，将该记录发送到客户端；否则在隔离级别不大于读提交时，释放该记录锁。

步骤7：获取当前记录所在单链表的下一条记录，并将其作为新的当前记录，并跳回步骤2。

#### 特殊情况下的加锁

1、UPDATE语句 与上述流程类似，不过，如果更新了二级索引，那么所有被更新的二级索引记录在更新之前都需要加 X型记录锁。

2、DETELE语句 与上述流程类似，不过，如果表中包含二级索引，那么删除记录前要加 X型记录锁。

3、**精确匹配**。**隔离级别不大于 读提交 时**，则不会为扫描区间的后面下一条记录加 记录锁；**隔离级别不小于 可重复读 时**，会为扫描区间后面的下一条记录加 **间隙锁**。

4、**不是精确匹配，没有找到匹配的记录**。当隔离级别不小于**可重复读**时，为扫描区间的后面下一条记录加 **临键锁** 。

5、当隔离级别不小于**可重复读**时，如果使用的**聚簇索引**，并且扫描的区间是**左闭区间**，而且**定位到的第一条聚簇索引记录 与 扫描区间中最小值相同**，那么会为该聚簇索引加 **记录锁**。

6、**无论哪个隔离级别**，只要是**唯一性搜索**，并且读到的记录被标记为“**已删除**”，为读取到的记录加 **记录锁**。

7、一般扫描记录是从左到右，如果**扫描是从右到左**，当**隔离级别不小于可重复读时**，匹配到第一条记录的下一条记录加 **间隙锁**。

### 半一致性读语句

**当隔离级别不大于读提交 且执行 UPDATE语句时**，称为半一致性读。

即UPDATE语句读到已经被其他事务加了X锁记录时，InnoDB会把最新版本的记录读出来，然后判断该版本是否与UPDATE语句中搜索条件相匹配。

不匹配，不对该记录加锁，跳到下一条记录；如果匹配，再次读取该记录并加锁。

目的：尽量减少UPDATE语句被别的语句阻塞。

### INSERT语句

INSERT语句一般情况下不需要在内存中生成锁结构，并单纯依靠 **隐式锁** 保护插入的记录。

插入记录前需要先在B+树中定位到记录的位置，**如果该位置的下一条记录被加了 间隙锁 或者 临键锁，那么当前事务会为该记录加上 插入意向锁**。

执行INSERT语句，在内存中生成锁结构的两种特殊情况：遇到重复键、外键检查。

**1、遇到重复键**

遇到重复记录的主键和唯一二级索引时会报错，但是在报错之前会给记录加 **S锁**。

主键重复，在不同隔离级别的加锁类型不同：

- 隔离级别为 **读未提交** 时，加的是 **记录锁**。
- 隔离级别**不小于可重复读**时，加的是 **临键锁**。

**二级唯一索引重复，不管什么隔离级别都加 临键锁。**

**2、外键检查**

待插记录的外键值可以在父表中匹配到，给父表的这条记录加 记录锁。

如果在父表中没有匹配到，会插入失败，并且：

- 隔离级别不大于读提交时，不加锁
- 隔离级别不小于可重复读时，加 间隙锁。

## 加锁情况总结

1. 普通SELECT语句不加锁，主要依赖MVCC机制。
2. 锁定读情况：
   1. 一般情况下，在隔离级别**不大于 读提交** 时，会为当前记录加**记录锁**。在隔离级别**不小于 可重复读** 时，会为记录加**临键锁**。
   2. **UPDATE语句更新二级索引** 或 **DELETE语句删除记录中包含二级索引**，需要加 **X型记录锁**。
   3. **精确匹配**。**隔离级别不大于 读提交 时**，则不会为扫描区间的后面下一条记录加 **记录锁**；**隔离级别不小于 可重复读 时**，会为扫描区间后面的下一条记录加 **间隙锁**。
   4. **不是精确匹配，没有找到匹配的记录**。当隔离级别不小于**可重复读**时，为扫描区间的后面下一条记录加 **临键锁** 。
   5. 当隔离级别不小于**可重复读**时，如果使用的**聚簇索引**，并且扫描的区间是**左闭区间**，而且**定位到的第一条聚簇索引记录 与 扫描区间中最小值相同**，那么会为该聚簇索引加 **记录锁**。
   6. **无论哪个隔离级别**，只要是**唯一性搜索**，并且读到的记录被标记为“**已删除**”，为读取到的记录加 **记录锁**。
   7. 一般扫描记录是从左到右，如果**扫描是从右到左**，当**隔离级别不小于可重复读时**，匹配到第一条记录的下一条记录加 **间隙锁**。
3. 半一致性读语句：**UPDATE语句读到已经被其他事务加了X锁记录时，InnoDB会把最新版本的记录读出来，然后判断该版本是否与UPDATE语句中搜索条件相匹配**。不匹配，不对该记录加锁，跳到下一条记录；**
   如果匹配，再次读取该记录并加锁**。
4. INSERT语句：
   1. 主键重复，在不同隔离级别的加锁类型不同：隔离级别为 **读未提交** 时，加的是 **记录锁**。隔离级别**不小于可重复读**时，加的是 **临键锁**。
   2. **二级唯一索引重复，不管什么隔离级别都加 临键锁。**
   3. 外键检查
      1. 待插记录的外键值可以在父表中**匹配到**，给父表的这条记录加 **记录锁**。
      2. 如果在父表中**没有匹配到**，会插入失败，并且：隔离级别不大于读提交时，不加锁；**隔离级别不小于可重复读时，加 间隙锁**。

## 查看事务的加锁情况

### 使用 information_schema 数据库中的表获取锁信息

在数据库 information_schema 中，有几个表和事务、锁有关。

1、`INNODB_TRX`：该表存储了InnoDB存储引擎当前正在执行的事务信息。包括：事务id，事务状态等。

其中重点有几个属性值得关注：

- `trx_tables_locked`：表示该事务目前加了多少个表级锁
- `trx_rows_locked`：表示该事务目前加了多少个行级锁（不包括隐式锁）
- `trx_lock_structs`：表示生成该事物生成了多少个内存结构的锁

2、`INNODB_LOCKS`：该表记录了一些锁信息：

- 如果一个事务想要获取到某个锁但未获取到，则记录该锁信息
- 如果一个事务获取到锁，但是这个锁阻塞了别的事务，则记录该锁信息。

3、`INNODB_LOCK_WAITS`：表明每个阻塞事务是因为获取不到那个事务持有的锁而阻塞。

### 使用 SHOW ENINGE INNODB STATUS 获取锁信息

略

## 死锁问题

T1和T2都在等待对方先释放掉与自己需要的锁相冲突的锁，因此T1和T2都不能继续执行，此时就称发生了死锁。

例子：

| 发生时间编号 | T1                                                           | T2                                                           |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1            | BEGIN;                                                       |                                                              |
| 2            |                                                              | BEGIN;                                                       |
| 3            | SELECT * FROM hero WHERE number=1 FOR UPDATE;                |                                                              |
| 4            |                                                              | SELECT * FROM hero WHERE number=3 FOR UPDATE;                |
| 5            | SELECT * FROM hero WHERE number=3 FOR UPDATE; <br />（此操作阻塞） |                                                              |
| 6            |                                                              | SELECT * FROM hero WHERE number=1 FOR UPDATE; <br />（死锁发生，记录日志，服务器回滚一个事务） |
|              |                                                              |                                                              |

**死锁检测机制：**检测死锁，会选择一个较小的事务（增删改记录条数较少），并向客户端发送一条报错信息。

可通过语句 `SELECT ENGINE INNODB STATUS` 查看最近一次死锁发生的信息。

## 参看：

- 《MySQL是怎样运行的》
- [把MySQL中的各种锁及其原理都画出来](https://zhuanlan.zhihu.com/p/149228460)
- [Mysql里的锁(排它锁、共享锁、行锁、表锁、间隙锁、临键锁、意向锁)](https://zhuanlan.zhihu.com/p/213814000)
- [什么是悲观锁和乐观锁](https://zhuanlan.zhihu.com/p/31537871)
- [MySQL锁总结](https://zhuanlan.zhihu.com/p/29150809)

# MySQL索引的18个问题

## 1 索引是什么？

索引是一种数据结构，协助快速查询和更新数据库表中的数据。

索引也是一种特殊的文件，包含数据库表里所有记录的引用指针。

可以类比字典，有拼音或者笔画的快速检索，找到对应的页码，打开后即可知道某一个key的全部值信息。

## 2 索引的优缺点？

优点：

- 大大加快检索速度。（创建索引最主要原因）
- 使用索引，在查询过程中使用优化隐藏器，提高系统性能。

缺点：

- 时间方面：创建索引和维护索引需要耗费时间，对索引数据增删改、索引也要维护，降低增删改效率。
- 空间方面：索引占用物理空间。

## 3 MySQL的索引类型

存储结构划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。

应用层次来分：

- 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引
- 唯一索引：索引列的值必须唯一，但允许有空值
- 复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
- 聚簇索引和非聚簇索引（下边介绍）

根据数据的物理顺序与键值的逻辑（索引）顺序关系： 聚集索引，非聚集索引

## 4 Mysql 索引底层数据结构选型（为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树？）

数据结构选型以如下图的user表进行分析：

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626100234-167661995740230.png" alt="user表部分数据示例" style="zoom: 50%;" />

### 哈希表

哈希表可以进行数据的快速检索。

哈希算法：也叫散列算法，就是把任意值(key)通过哈希函数变换为固定长度的 key 地址，通过这个地址进行数据查询的数据结构。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626100002-167661995740332.png" alt="哈希表原理" style="zoom:67%;" />

如果需要检索`id=7`的数据，sql如下：

```sql
select *
from user
where id = 7;
```

哈希算法快速检索数据的计算过程：首先计算存储 id=7 的数据的物理地址 addr=hash(7)=4231，而 4231 映射的物理地址是 0x77，0x77 就是 id=7 存储的额数据的物理地址，通过该独立地址可以找到对应
user_name='g'这个数据。

但是hash算法可能出现**碰撞问题**，即hash函数可能计算相同的key值，不同的key映射到了同一个结果。解决碰撞问题的常见方法是**链地址法**
：碰撞数据使用链表连接，计算hash值后，判断该值如果有碰撞，遍历到链表，直到找到真正的key所对应的数据为止。

![hash碰撞-链地址法](images/MySQL%E6%80%BB%E7%BB%93/20210626101110-167661995740334.png)

从算法时间复杂度分析来看，哈希算法时间复杂度为 O（1），检索速度非常快。比如查找 id=7 的数据，哈希索引只需要计算一次就可以获取到对应的数据，检索速度非常快。但是 Mysql 并没有采取哈希作为其底层算法。

```
select * from user where id >3;
```

即hash算法针对范围查找效率太低，需要把所有数据找出来加载到内存，然后再在内存里筛选筛选目标范围内的数据。

**总结：hash表可以快速检索数据，但是范围查找效率低。所以不适合作为MySQL的索引数据结构**。

### 二叉查找数（BST）

二叉查找树支持快速查找数据，时间复杂度为O(logn)。如下图所示，只需计算三次即可找到`id=7`的数据。需要考虑其是否能解决hash表范围查找效率低的问题。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626101831-167661995740336.png" alt="image-20210626101831123" style="zoom:67%;" />

二叉查找数按序排列（从左到右升序），如果想找到`id>5`的数据，只需要找到**节点6及其右子树**的数据即可，范围查找比较容易实现。

**普通二叉树的致命缺点**：极端情况下会退化为线性链表，时间复杂度为O(n)，性能急剧下降，如下图：

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626102314-167661995740338.png" alt="二叉树退化为线性链表"  />

数据库表的主键id一般为自增，上述的线性结构查找问题必然出现，而且频率还很高。

**总结：二叉查找数查询效率高，而且可以解决hash表范围查询效率低的问题，但是会频繁出现不平衡退化问题导致查询效率低的问题，所以不适合作为MySQL索引的数据结构**。

### 红黑树

二叉查找树不平衡，可以通过树节点的自动旋转和调整来解决，从而保证二叉树的查找性能。最常见的思路是平衡二叉树和红黑树。

红黑树可以自动调整树的结构，当二叉树不平衡时，红黑树自动左右旋转和节点变色，保持基本平衡，时间复杂度为O(logn)，查询效率不会降低。如下图，红黑树查找`id=7`的节点只需要查找4次：

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626105121-167661995740340.png" alt="红黑树查找节点" style="zoom: 80%;" />

**但是红黑树也有缺点，即“右倾”现象**（参看下图），虽然没有二叉树退化那么夸张，但数据库主键基本都是自增，面对成千上百万的数据，这查询效率可想而知。

![红黑树“右倾”现象](images/MySQL%E6%80%BB%E7%BB%93/20210626105920-167661995740342.png)

**总结：红黑树查询效率与二叉查找树相似，极端退化情况比平衡二叉树好，但是也没能达到预期，所以不适合MySQL索引的数据结构**。

### 平衡二叉树（AVL）

平衡二叉树，是绝对平衡的。

AVL 树顺序插入 1~7 个节点，查找 id=7 所要比较节点的次数为 3。

AVL 树插入 1~16 个节点，查找 id=16 需要比较的节点数为 4。从查找效率而言，AVL 树查找的速度要高于红黑树的查找效率（AVL 树是 4 次比较，红黑树是 6 次比较）。

从树的形态看来，AVL 树不存在红黑树的“右倾”问题。大量的顺序插入不会导致查询性能的降低，这从根本上解决了红黑树的问题。

**AVL 树的优点**：

- 查询效率高O(logn)，不存在极端情况。
- 可以进行范围查找和排序。

**但是为什么不选取AVL树作为MySQL索引的数据结构**？

**主要是磁盘IO因素的影响**。如果使用AVL树，每一个树节点，只存储一个数据。如果查询`id=7`的数据，需要比对三次树节点，即进行三次磁盘IO操作，如果数据量大了，那磁盘IO的次数会很高，消耗大量的时间。

所以，**设计数据库索引的时候，还需要考虑怎么尽可能减少磁盘的IO次数**。

**磁盘读取1B和1KB的数据消耗的时间基本是一样的，所以可以在一个节点存储更多的数据，即一次磁盘IO读取更多数据，即可解决问题。所以就考虑到了B树**。

### B树（B-树）

B树的理解参考：[平衡二叉树、B树、B+树、B*树 理解其中一种你就都明白了](https://zhuanlan.zhihu.com/p/27700617)

B树，平衡多路查找树，又称B-树。

**如果每个节点限制最多存储两个key（即二叉树），一个节点如果超过两个key会自动分裂。**

比如下面这个存储了 7 个数据 B 树，只需要查询两个节点就可以知道 id=7 这数据的具体位置，也就是两次磁盘 IO 就可以查询到指定数据，优于 AVL 树。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626112940-167661995740344.png" alt="B树7节点（限制单节点key=2）" style="zoom:80%;" />

如果是一个存储了 16 个数据的 B 树，同样每个节点最多存储 2 个 key，查询 id=16 这个数据需要查询比较 4 个节点，也就是经过 4 次磁盘 IO。看起来查询性能与 AVL 树一样。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626115100-167661995740346.png" alt="B树16节点（限制单节点key=2）" style="zoom:80%;" />

**如果限制每个节点可以存储6个key。**

一个存储了 7 个数据的 B 树，查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626115252-167661995740348.png" alt="B树7节点（限制单节点key=6）" style="zoom:80%;" />



一个存储了 16 个数据的 B 树，查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。相对于 AVL 树而言磁盘 IO 次数降低为一半。

![B树16节点（限制单节点key=6）](images/MySQL%E6%80%BB%E7%BB%93/20210626115329-167661995740350.png)

**B 树作数据库索引优点**：

- 优秀检索速度，时间复杂度：B 树的查找性能等于 O（h*logn），其中 h 为树高，n 为每个节点关键词的个数；
- 尽可能少的磁盘 IO，加快了检索速度；
- 可以支持范围查找。

B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，但是数据分布在各个节点之中，每个节点存储的数据量是有限的，MySQL希望一个节点可以尽可能多的存储数据，因此采用了B+树。

### B+树

- B树一个节点存储的是数据，一个节点中存储不了太多数据；而B+树非叶子节点存储的是地址，叶子结点存储的是数据，可以存储更多数据。
- B+数叶子结点采用链表串联，更便于范围查找。而B树需要中序遍历。

![B+树](images/MySQL%E6%80%BB%E7%BB%93/20210626115803-167661995740352.png)

## 5 Innodb 引擎和 Myisam 引擎对索引的实现

Myisam 虽然数据查找性能极佳，但是不支持事务处理。Innodb 最大的特色就是支持了 ACID 兼容的事务功能，而且他支持行级锁。Mysql 建立表的时候就可以指定引擎。B+树作为 Mysql
的索引的数据结构非常合适，那么两种引擎是怎么实现的呢？

在执行建表语句并指定引擎后，Innodb 生成的文件有：

- frm:创建表的语句
- idb:表里面的数据+索引文件

Myisam 生成的文件有:

- frm:创建表的语句
- MYD:表里面的数据文件（myisam data）
- MYI:表里面的索引文件（myisam index）

从生成的文件看来，这两个引擎底层数据和索引的组织方式并不一样，MyISAM 引擎把数据和索引分开了，一人一个文件，这叫做**非聚集索引方式**；Innodb 引擎把数据和索引放在同一个文件里了，这叫做**聚集索引方式**。

接下来从底层实现的角度分析。

**MyISAM 引擎的底层实现（非聚集索引方式）**

MyISAM 用的是非聚集索引方式，即数据和索引落在不同的两个文件上。MyISAM 在建表时**以主键作为 KEY 来建立主索引 B+树，树的叶子节点存的是对应数据的物理地址**。**通过这个物理地址后，就可以到 MyISAM
数据文件中直接定位到具体的数据记录了**。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626154923.png" alt="MyISAM 引擎的底层实现" style="zoom: 50%;" />

在为其他字段添加索引时，同样会生成对应的索引树，检索方式与上述相同。

**Innodb 引擎的底层实现（聚集索引方式）**

InnoDB 是的主键索引是聚集索引方式，数据和索引都存储在同一个文件里。首先 InnoDB 会根据主键 ID 作为 KEY 建立索引 B+树，而 B+树的叶子节点存储的是主键 ID
对应的数据。在根据主键ID查询时，会查询这颗主键ID的索引树，找到对应叶子结点的数据。

建表的时候，InnoDB就会建好主键ID的索引树，这也是为什么 Mysql 在建表时要求必须指定主键的原因。

在为其他字段建立索引时，非叶子结点存储当前字段的key，**叶子结点存储主键的key**。得到主键key后，才会在主键索引树中找到当前字段所对应的数据。

<img src="images/MySQL%E6%80%BB%E7%BB%93/20210626155854.png" alt="Innodb 引擎的底层实现" style="zoom:50%;" />



**为什么 InnoDB 只在主键索引树的叶子节点存储了具体数据，但是其他索引树却不存具体数据呢，而要多此一举先找到主键，再在主键索引树找到对应的数据呢**？

因为 InnoDB
要节省存储空间。一个表里可能有很多个索引，如果给每个加了索引的字段生成索引树，都存储了具体数据，那么这个表的索引数据文件就变得非常巨大（数据极度冗余了）。从节约磁盘空间的角度来说，没有必要，通过这种看似“多此一举”的步骤，在牺牲较少查询的性能下节省了巨大的磁盘空间。

**为什么InnoDB 和MyISAM 对比，MyISAM 查询性能更好？**

从上面索引文件数据文件的设计来看也可以看出原因：

- **MyISAM 直接找到物理地址后就可以直接定位到数据记录**。
- **InnoDB 查询到叶子节点后，还需要再查询一次主键索引树，才可以定位到具体数据**。

等于 MyISAM 一步就查到了数据，但是 InnoDB 要两步，所以 MyISAM 查询性能更高。

## 6 InnoDB中一棵B+树能存多少行数据？

**约 2 千万**

参看：

- [面试题：InnoDB中一棵B+树能存多少行数据？](https://zhuanlan.zhihu.com/p/67982911)
- [面试题：mysql 一棵 B+ 树能存多少条数据？](https://zhuanlan.zhihu.com/p/379092178)

## 7 聚簇索引和非聚簇索引

> 聚簇索引是叶子结点存储整行数据，即数据与索引存储在一块，找到索引也就找到了数据。InnoDB的主键索引是聚簇索引。

> 非聚簇索引是叶子结点存储了主键的值，也被称为二级索引。

- 非聚集索引与聚集索引的区别在于**非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键**。
- 对于InnoDB来说，非主键的索引查到了主键的值，还需要去主键索引树再次查找数据，称这个过程为**回表**。
- 通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。
- MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。

## 8 非聚簇索引一定会回表查询吗？（覆盖索引）

不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为"覆盖索引"。

例子：假设在学生表的成绩（`score`）上建立了索引，那么当进行`select score from student where score > 90`的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。

## 9 联合索引是什么？为什么需要注意联合索引中的顺序？

> 联合索引：使用多个字段同时建立一个索引。

在联合索引中，只有按照建立索引时的字段顺序使用，才能命中。

例子：假设建立“name，age，school”的联合索引，那么索引的排序为: 先按照name排序进行索引，如果name相同，则按照age排序索引，如果age的值也相等，则按照school进行排序索引。

因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。

## 10 MySQL的最左前缀原则?

最左前缀原则就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配。

例子：比如`a = 1 and b = 2 and c > 3 and d = 4 `如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

`=`和`in`可以乱序，比如`a = 1 and b = 2 and c = 3` 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会优化成索引可以识别的形式。

## 11 前缀索引？

可能出现建立索引字段非常长的情况，这样既占用内存空间，也不利于维护。所以可以选取字段前面的公共部分作为一个索引，大大提升检索效率。但是`ORDER BY`和`GROUP BY`不支持前缀索引 。

流程：

1. 计算完整列的选择性 :`select count(distinct col_1)/count(1) from table_1`
2. 计算不同前缀长度的选择性 :`select count(distinct left(col_1,4))/count(1) from table_1`
3. 找到最优长度之后，创建前缀索引 :`create index idx_front on table_1 (col_1(4))`

注意事项：

- 前缀索引是一种能使索引更小，更快的有效办法，但另一方面也有其缺点：mysql无法使用其前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描
- 要明确使用前缀索引的目的与优势
  - 大大节约索引空间，从而提高索引效率
  - 对于 BOLB 、 TEXT 或者很长的 VARCHAR 类型的列，必须使用前缀索引,因为 MySQL 不允许索引这些列的完整长度
- 前缀索引会降低索引的选择性
  - 关于索引的选择性，它是指不重复的索引值（也称为基数cardinality)和数据表的记录总数的比值，范围从1/(数据表记录总数)
    到1之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。选择性为1的索引叫唯一索引，这是最好的索引选择性，性能也是最好的。
- 真正的难点在于：要选择足够长的前缀以保证较高的选择性，同时又不能太长， 前缀的长度应该使前缀索引的选择性接近索引整个列，即前缀的基数应该接近于完整列的基数

前缀索引分析可参看：[MySQL 前缀索引](https://www.cnblogs.com/niuben/p/13188277.html)

## 12 索引下推？

> MySQL 5.6引入了索引下推优化。默认开启，使用`SET optimizer_switch = ' index_condition_pushdown=off ';`可以将其关闭。有了索引下推优化，可以在**减少回表次数**。

官方解释：

在 people_table中有一个二级索引(zipcode，lastname，firstname)
，查询语句：`SELECT * FROM people WHERE zipcode='95054' AND lastname LIKE '%etrunia%' AND address LIKE '%Main Street%' ;`

如果没有使用索引下推技术，则MySQL会通过`zipcode='95054'`从存储引擎中查询对应的数据，返回到MySQL服务端（**回表**
），然后MySQL服务端基于`lastname LIKE '%etrunia%' AND address LIKE '%Main Street%'`来判断数据是否符合条件。

如果使用了索引下推技术，则MYSQL首先会返回符合`zipcode='95054'`的索引，然后根据`lastname LIKE '%etrunia%' AND address LIKE '%Main Street%'`
来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。

注意：**在InnoDB中索引下推只对二级索引有效**。

## 13 怎么查看MySQL语句有没有用到索引？

可以通过explain查看sql语句的执行计划，通过执行计划来分析索引使用情况，只需要将explain添加在sql语句之前即可。

表中的索引：

![表中的索引](images/MySQL%E6%80%BB%E7%BB%93/20210626214501-167661995740356.png)

通过explain查看sql是否用到索引：

![explain查看sql的结果](images/MySQL%E6%80%BB%E7%BB%93/20210626214556-167661995740358.png)

- type 的信息很明显的体现是否用到索引，它提供了判断查询是否高效的重要依据依据，如const(主键索引或者唯一二级索引进行等值匹配的情况下)，ref(普通的⼆级索引列与常量进⾏等值匹配)，index(扫描全表索引的覆盖索引)
  。性能如下：`ALL < index < range ~ index_merge < ref < eq_ref < const < system`。 `ALL` 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.
  而 `index` 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快。
- select_type：select关键字对应的那个查询的类型，如SIMPLE，PRIMARY，SUBQUERY，DEPENDENT，SNION 。
- table：每个查询对应的表名 。
- possible_key：查询中可能用到的索引
- key：此字段是 MySQL 在当前查询时所真正使用到的索引。
- filtered：查询器预测满足下一次查询条件的百分比 。
- rows: 显示MySQL认为它执行查询时必须检查的行数。这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好。
- extra：表示额外信息。

## 14 什么情况下不走索引（索引失效）？

1. **使用`!=` 或者 `<>` 导致索引失效**。
2. **类型不一致导致的索引失效**。
3. **函数导致的索引失效**。如：`SELECT * FROM user WHERE DATE(create_time) = '2020-09-03';` 如果`create_time`添加了索引，索引会失效。
4. **运算符导致的索引失效**。如：`SELECT * FROM user WHERE age - 1 = 20;` 如果对列进行了（+，-，*，/，!）, 那么都将不会走索引。
5. **`OR`引起的索引失效**。OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之`OR`右侧字段索引失效。
6. **模糊搜索导致的索引失效**。当`%`放在匹配字段前是不走索引的，放在后面才会走索引。
7. **`NOT IN`、`NOT EXISTS`导致索引失效**。

## 15 为什么官方建议使用自增长数字主键作为索引？

**建议使用有序的自增ID作为主键**

提高效率主要体现在：

- 提高范围查询效率；
- 增加排序效率；
- 提高扫表能力,顺序访问。

结合B+树的特点，一个表有多少个索引就会有多少颗B+树，MySQL的数据都是按顺序保存在树的叶子结点上的。

mysql 在底层又是以数据页为单位来存储数据的，一个数据页大小默认为 16k（可以自定义大小）。如果一个数据页存满了，mysql 就会去申请一个新的数据页来存储数据。

- 如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。
- 如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。当往一个快满或已满的数据页中插入数据时，新插入的数据会将数据页写满，mysql
  就需要申请新的数据页，并且把上个数据页中的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的。

![InnoDB逻辑结构](images/MySQL%E6%80%BB%E7%BB%93/20210626221023.png)

**在满足业务需求的情况下，尽量使用占空间更小的主键**

- 主键占用空间越大，每个页存储的主键个数越少，路树就越少，B+树的深度会边长，导致IO次数会变多。
- 普通索引的叶子节点上保存的是主键 id 的值，如果主键 id 占空间较大的话，那将会成倍增加 mysql 空间占用大小。

![索引流程图](images/MySQL%E6%80%BB%E7%BB%93/20210626220947.png)

**总结：使用自增主键可以提高效率（范围查询、排序、扫表），而且自增数字占用更小的空间，可以存储更多的数据。**

## 16 如何创建索引？

**1、在执行`CREATE TABLE`时创建索引**

```sql
CREATE TABLE user_index2
(
    id          INT auto_increment PRIMARY KEY,
    name        VARCHAR(16),
    id_card     VARCHAR(18),
    information text,
    INDEX (id_card)
);
```

**2、使用`ALTER TABLE`命令去增加索引**

```sql
ALTER TABLE table_name
    ADD INDEX index_name (column_list);
```

ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。

## 17 创建索引时需要注意什么？建索引的原则有哪些？

注意事项：

- **较频繁的作为查询条件的字段应该创建索引**。
- **唯一性太差的字段不适合单独创建索引**，即使该字段频繁作为查询条件。
- **更新非常频繁的字段不适合创建索引**。
- **非空字段**：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值。
- **取值离散大的字段**（变量各个取值之间的差异程度），将其列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高。
- **索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

原则：

- **最左前缀匹配原则**。在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。
- **`=`和`in`可以乱序**。比如`a = 1 and b = 2 and c = 3` 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。
- **尽量选择区分度高的列作为索引**。区分度的公式是`count(distinct col)/count(*)`，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1。
- **索引列不能参与计算**。计算代表逻辑计算和使用函数，会使索引失效。
- **尽量的扩展索引，不要新建索引**。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

## 18 使用索引查询一定能提高查询的性能吗？

使用索引查询不一定能提高查询性能.

**通常通过索引查询数据比全表扫描要快，但是我们也必须注意到使用的代价**。

索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。

这意味着每条记录的`INSERT`，`DELETE`，`UPDATE`将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。

索引范围查询(INDEX RANGE SCAN)适用于两种情况:

1. 基于一个范围的检索，一般查询返回结果集小于表中记录数的30%。

2. 基于非唯一性索引的检索。

否则索引范围查询的效率会大大降低。

## 19. mysql索引对Null值如何处理的？

- 只要列中包含有NULL值都将不会被包含在索引中
- 复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。

所以我们在数据库设计时不要让字段的默认值为NULL。

## 参考

- [深入理解 Mysql 索引底层原理](https://zhuanlan.zhihu.com/p/113917726) （mysql索引的底层数据结构及实现）
- [我以为我对Mysql索引很了解，直到我遇到了阿里的面试官](https://zhuanlan.zhihu.com/p/78982303) （mysql索引常见问题）
- [MySQL索引连环18问！](https://zhuanlan.zhihu.com/p/364041898) （很全，基本都是常用的）
- [mysql前缀索引的索引选择性](https://blog.csdn.net/dhrome/article/details/72853153)
- [MySQL 前缀索引](https://www.cnblogs.com/niuben/p/13188277.html)
- [面试题：InnoDB中一棵B+树能存多少行数据？](https://zhuanlan.zhihu.com/p/67982911)
- [面试题：mysql 一棵 B+ 树能存多少条数据？](https://zhuanlan.zhihu.com/p/379092178)
- [mysql 如何查看是否有用到索引_mysql 如何查看sql查询是否用到索引](https://blog.csdn.net/weixin_33816685/article/details/113276900)
- [mysql innodb为什么建议使用自增数字作为主键？](https://www.cnblogs.com/kancy/p/13458991.html)
- [MySQL 如何创建索引？怎么优化？](https://www.cnblogs.com/lfs2640666960/p/9147768.html)

## 参考

- [深入理解 Mysql 索引底层原理](https://zhuanlan.zhihu.com/p/113917726) （mysql索引的底层数据结构及实现）
- [我以为我对Mysql索引很了解，直到我遇到了阿里的面试官](https://zhuanlan.zhihu.com/p/78982303) （mysql索引常见问题）
- [MySQL索引连环18问！](https://zhuanlan.zhihu.com/p/364041898) （很全，基本都是常用的）
- [mysql前缀索引的索引选择性](https://blog.csdn.net/dhrome/article/details/72853153)
- [MySQL 前缀索引](https://www.cnblogs.com/niuben/p/13188277.html)
- [面试题：InnoDB中一棵B+树能存多少行数据？](https://zhuanlan.zhihu.com/p/67982911)
- [面试题：mysql 一棵 B+ 树能存多少条数据？](https://zhuanlan.zhihu.com/p/379092178)
- [mysql 如何查看是否有用到索引_mysql 如何查看sql查询是否用到索引](https://blog.csdn.net/weixin_33816685/article/details/113276900)
- [mysql innodb为什么建议使用自增数字作为主键？](https://www.cnblogs.com/kancy/p/13458991.html)
- [MySQL 如何创建索引？怎么优化？](https://www.cnblogs.com/lfs2640666960/p/9147768.html)

